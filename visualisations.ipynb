{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisations and familiarizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains our data visualisations, cleaning of the data and some\n",
    "familiarizations to find relationships between columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the imports here, this makes it easy to create a requirements.txt file\n",
    "# later, which can be used by whoever is grading us to install everything!\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd\n",
    "\n",
    "# decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reader import get_data_dict\n",
    "data = get_data_dict('./data/alzheimers_disease_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal and external factors\n",
    "\n",
    "The dataset contains all sorts of different metrics for a patient. These metrics can be divided into three categories:\n",
    "- Metadata: `PatientID`, `Diagnosis` and `DoctorInCharge` (since this one is just the same value everywhere)\n",
    "- Internal factors: `Age`, `Gender`, `Ethnicity`, `BMI`, `FamilyHistoryAlzheimers`, `CardiovascularDisease`, `Diabetes`, `Depression`, `Hypertension`, `SystolicBP`, `DiastolicBP`, `CholesterolTotal`, `CholesterolLDL`, `CholesterolHDL`, `CholesterolTriglycerides`, `MMSE`, `FunctionalAssessment`, `MemoryComplaints`, `BehavioralProblems`, `ADL`, `Confusion`, `Disorientation`, `PersonalityChanges`, `DifficultyCompletingTasks` and `Forgetfulness`\n",
    "- External factors: `EducationLevel`, `Smoking`, `AlcoholConsumption`, `PhysicalActivity`, `DietQuality` and `SleepQuality`\n",
    "\n",
    "The metadata is not important for the tests and experiments on the data, as this says nothing about the condition of the patient. The only column here that is important is `Diagnosis`, as it tells us whether or not a patient actually has Alzheimer's disease. This is, for example, the target vector we can use for a regression model.\n",
    "\n",
    "The internal and external factors can be examined, since these actually tell us something about the health of the patient. These could have an effect on whether or not someone has Alzheimer's disease and therefore they can be used to, for example, make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into the three categories described above:\n",
    "metadata_keys = [\"PatientID\", \"Diagnosis\", \"DoctorInCharge\"]\n",
    "internal_factors_keys = [\n",
    "    \"Age\", \"Gender\", \"Ethnicity\", \"BMI\", \"FamilyHistoryAlzheimers\",\n",
    "    \"CardiovascularDisease\", \"Diabetes\", \"Depression\", \"Hypertension\",\n",
    "    \"SystolicBP\", \"DiastolicBP\", \"CholesterolTotal\", \"CholesterolLDL\",\n",
    "    \"CholesterolHDL\", \"CholesterolTriglycerides\", \"MMSE\", \"FunctionalAssessment\",\n",
    "    \"MemoryComplaints\", \"BehavioralProblems\", \"ADL\", \"Confusion\",\n",
    "    \"Disorientation\", \"PersonalityChanges\", \"DifficultyCompletingTasks\",\n",
    "    \"Forgetfulness\", \"HeadInjury\"\n",
    "]\n",
    "external_factors_keys = [\"EducationLevel\", \"Smoking\", \"AlcoholConsumption\",\n",
    "                         \"PhysicalActivity\", \"DietQuality\", \"SleepQuality\"]\n",
    "\n",
    "from data_reader import split_data\n",
    "metadata, internal_factors, external_factors = split_data()\n",
    "\n",
    "print(\"Metadata:\", list(metadata.keys()))\n",
    "print(\"Internal Factors:\", list(internal_factors.keys()))\n",
    "print(\"External Factors:\", list(external_factors.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the internal factors into an image with two columns\n",
    "num_plots = len(internal_factors)\n",
    "columns = 3\n",
    "rows = (num_plots + columns - 1) // columns\n",
    "\n",
    "fig, axes = plt.subplots(rows, columns, figsize=(10, rows * 4))\n",
    "fig.suptitle('The internal factors in histograms', fontsize=16)\n",
    "axes = axes.flatten()\n",
    "\n",
    "mean_line = Line2D([0], [0], color='red', linestyle='dashed', label='Mean')\n",
    "median_line = Line2D([0], [0], color='green', linestyle='dashed', label='Median')\n",
    "std_line = Line2D([0], [0], color='orange', linestyle='dashed', label='Mean ±1 std.')\n",
    "\n",
    "for i, (key, values) in enumerate(internal_factors.items()):\n",
    "    axes[i].hist(values, bins=20, color='skyblue', edgecolor='blue')\n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values)\n",
    "    median = np.median(values)\n",
    "\n",
    "    axes[i].axvline(mean, color='red', linestyle='dashed')\n",
    "    axes[i].axvline(median, color='green', linestyle='dashed')\n",
    "    axes[i].axvline(mean + std, color='orange', linestyle='dashed')\n",
    "    axes[i].axvline(mean - std, color='orange', linestyle='dashed')\n",
    "\n",
    "    axes[i].set_title(key)\n",
    "    axes[i].set_xlabel('Value')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "fig.legend(handles=[mean_line, median_line, std_line], loc='upper center',\n",
    "           ncol=3, bbox_to_anchor=(0.5, 0.975))\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.975])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the internal factors into an image with two columns\n",
    "num_plots = len(external_factors)\n",
    "columns = 3\n",
    "rows = (num_plots + columns - 1) // columns\n",
    "\n",
    "fig, axes = plt.subplots(rows, columns, figsize=(10, rows * 4))\n",
    "fig.suptitle('The internal factors in histograms', fontsize=16)\n",
    "axes = axes.flatten()\n",
    "\n",
    "mean_line = Line2D([0], [0], color='red', linestyle='dashed', label='Mean')\n",
    "median_line = Line2D([0], [0], color='green', linestyle='dashed', label='Median')\n",
    "std_line = Line2D([0], [0], color='orange', linestyle='dashed', label='Mean ±1 std.')\n",
    "\n",
    "for i, (key, values) in enumerate(external_factors.items()):\n",
    "    axes[i].hist(values, bins=20, color='skyblue', edgecolor='blue')\n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values)\n",
    "    median = np.median(values)\n",
    "\n",
    "    axes[i].axvline(mean, color='red', linestyle='dashed')\n",
    "    axes[i].axvline(median, color='green', linestyle='dashed')\n",
    "    axes[i].axvline(mean + std, color='orange', linestyle='dashed')\n",
    "    axes[i].axvline(mean - std, color='orange', linestyle='dashed')\n",
    "\n",
    "    axes[i].set_title(key)\n",
    "    axes[i].set_xlabel('Value')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "fig.legend(handles=[mean_line, median_line, std_line], loc='upper center',\n",
    "           ncol=3, bbox_to_anchor=(0.5, 0.955))\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.955])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings\n",
    "There are a few columns that seem to follow just a few categories:\n",
    "- Internal factors: `Gender`, `Ethnicity`, `FamilyHistoryAlzheimers`,\n",
    "`CardiovascularDisease`, `Diabetes`, `Depression`, `Hypertension`,\n",
    "`MemoryComplaints`, `BehavioralProblems`, `Confusion`, `Disorientation`,\n",
    "`PersonalityChanges`, `DifficultyCompletingTasks`, `Forgetfulness` and\n",
    "`HeadInjury`\n",
    "- External factors: `EducationLevel` and `Smoking`\n",
    "\n",
    "Out of these, `Ethnicity` and `EducationLevel` have more than two categories,\n",
    "while the other ones only have two. Something that stands out in the columns\n",
    "with only two categories, is that usually the 'No' bar (corresponding to\n",
    "value 0) is much larger than the 'Yes' bar (corresponding to value 1). The only\n",
    "categorical data where this is not the case is the `Gender` column, which shows\n",
    "that the two genders are represented roughly equally. A next step for cleaning\n",
    "the columns mentioned above is to attach a more meaningful label to the numbers.\n",
    "\n",
    "For all colums that do not follow a few categories we see that the median and\n",
    "mean are roughly at the same value. Besides that, none of the columns seem to\n",
    "follow some sort of distribution. However, it also does not seem like each\n",
    "symptom is uniformly distributed among the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach the correct labels to categorical data columns\n",
    "yesno_cols = ['FamilyHistoryAlzheimers', 'CardiovascularDisease', 'Diabetes',\n",
    "              'Depression', 'Hypertension', 'MemoryComplaints', 'BehavioralProblems',\n",
    "              'Confusion', 'Disorientation', 'PersonalityChanges', 'DifficultyCompletingTasks',\n",
    "              'Forgetfulness', 'HeadInjury', 'Smoking']\n",
    "labeled_data = {}\n",
    "for key in yesno_cols:\n",
    "    labeled_data[key] = np.where(\n",
    "        np.array(data[key]) == 0, 'no', 'yes').tolist()\n",
    "labeled_data['Gender'] = np.where(\n",
    "    np.array(data['Gender']) == 0, 'male', 'female').tolist()\n",
    "mapping = {0: \"Caucasian\", 1: \"African American\", 2: \"Asian\", 3: \"Other\"}\n",
    "labeled_data['Ethnicity'] = np.vectorize(\n",
    "    mapping.get)(data['Ethnicity']).tolist()\n",
    "mapping = {0: \"none\", 1: \"high school\", 2: \"bachelor\", 3: \"higher\"}\n",
    "labeled_data['EducationLevel'] = np.vectorize(\n",
    "    mapping.get)(data['EducationLevel']).tolist()\n",
    "\n",
    "for key in labeled_data.keys():\n",
    "    print(f'{key}: {labeled_data[key][:5] + ['...']}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding outliers\n",
    "Using boxplots it is possible to find out if any of the columns have outliers, which would need to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(data):\n",
    "    \"\"\"\n",
    "    Detect outliers in numerical columns using the Interquartile Range (IQR) method.\n",
    "    \"\"\"\n",
    "    outliers = {}\n",
    "    \n",
    "    # Identify numerical columns\n",
    "    numerical_columns = [\n",
    "        col for col in data.keys() \n",
    "        if all(isinstance(x, (int, float)) for x in data[col])\n",
    "    ]\n",
    "    \n",
    "    for column in numerical_columns:\n",
    "        # Calculate Q1, Q3, and IQR\n",
    "        values = data[column]\n",
    "        Q1 = np.percentile(values, 25)\n",
    "        Q3 = np.percentile(values, 75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Define outlier boundaries\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Find outliers\n",
    "        column_outliers = [\n",
    "            (i, val) for i, val in enumerate(values) \n",
    "            if val < lower_bound or val > upper_bound\n",
    "        ]\n",
    "        \n",
    "        outliers[column] = {\n",
    "            'outliers': column_outliers,\n",
    "            'lower_bound': lower_bound,\n",
    "            'upper_bound': upper_bound,\n",
    "            'total_outliers': len(column_outliers),\n",
    "            'outlier_percentage': (len(column_outliers) / len(values)) * 100\n",
    "        }\n",
    "    \n",
    "    return outliers\n",
    "\n",
    "def visualize_outliers(data, outliers):\n",
    "    \"\"\"\n",
    "    Create box plots to visualize outliers in numerical columns.\n",
    "    \"\"\"\n",
    "\n",
    "    numerical_columns = [\n",
    "        col for col in data.keys() \n",
    "        if all(isinstance(x, (int, float)) for x in data[col])\n",
    "    ]\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.title('Outliers in Numerical Columns', fontsize=16)\n",
    "    sns.boxplot(data=[data[col] for col in numerical_columns])\n",
    "    plt.xticks(range(len(numerical_columns)), numerical_columns, rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def print_outlier_summary(outliers):\n",
    "    \"\"\"\n",
    "    Print a summary of outliers for each numerical column.\n",
    "    \"\"\"\n",
    "    print(\"\\nOutlier Detection Summary:\")\n",
    "    for column, info in outliers.items():\n",
    "        print(f\"\\n{column}:\")\n",
    "        print(f\"  Total Outliers: {info['total_outliers']}\")\n",
    "        print(f\"  Percentage of Outliers: {info['outlier_percentage']:.2f}%\")\n",
    "        print(f\"  Lower Bound: {info['lower_bound']}\")\n",
    "        print(f\"  Upper Bound: {info['upper_bound']}\")\n",
    "        \n",
    "        # Print first 5 outliers if any exist\n",
    "        if info['outliers']:\n",
    "            print(\"  Sample Outliers (index, value):\")\n",
    "            for idx, (i, val) in enumerate(info['outliers'][:5]):\n",
    "                print(f\"    {i}: {val}\")\n",
    "            if len(info['outliers']) > 5:\n",
    "                print(f\"    ... and {len(info['outliers']) - 5} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = detect_outliers({key: value for key, value in data.items() if key != 'PatientID'})\n",
    "print_outlier_summary(outliers)\n",
    "visualize_outliers({key: value for key, value in data.items() if key != 'PatientID'}, outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons\n",
    "\n",
    "Some variables might show a significant difference between people with and without Alzheimer's disease. Based on whether or not a patient got a diagnosis, the data is split into two halves. Those two halves are compared in the plots below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(labeled_data.keys())\n",
    "num_labels = len(labels)\n",
    "\n",
    "max_cols = 3\n",
    "num_rows = -(-num_labels // max_cols)\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, max_cols, figsize=(15, num_rows * 5))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, label in enumerate(labels):\n",
    "    alz_indexes = np.where(np.array(data['Diagnosis']) == 1)[0].tolist()\n",
    "    alz_data = []\n",
    "    normal_data = []\n",
    "    for i in range(len(data[label])):\n",
    "        if i in alz_indexes:\n",
    "            alz_data.append(data[label][i])\n",
    "        else:\n",
    "            normal_data.append(data[label][i])\n",
    "\n",
    "    ax = axes[idx]\n",
    "    ax.hist(alz_data, color='orange', align='right', rwidth=0.5, density=True, label='Alzheimer\\'s')\n",
    "    ax.hist(normal_data, color='blue', align='left', rwidth=0.5, density=True, label='Normal')\n",
    "    ax.axvline(x=np.mean(normal_data), label='Mean for normal', color='skyblue', lw=3, ls='-.')\n",
    "    ax.axvline(x=np.mean(alz_data), label='Mean for Alzheimer\\'s', color='red', lw=3, ls='--')\n",
    "    ax.set_title(label)\n",
    "    ax.legend()\n",
    "    if label == 'Gender':\n",
    "        ax.set_xticks([0, 1], ['Male', 'Female'])\n",
    "    elif label == 'EducationLevel':\n",
    "        ax.set_xticks([0, 1, 2, 3], ['None', 'High school', 'Bachelor\\'s', 'Higher'])\n",
    "    elif label == 'Ethnicity':\n",
    "        ax.set_xticks([0, 1, 2, 3], ['Caucasian', 'African American', 'Asian', 'Other'])\n",
    "    else:\n",
    "        ax.set_xticks([0, 1], ['No', 'Yes'])\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "for idx in range(len(labels), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.955])\n",
    "plt.suptitle('All categorical data columns compared (0 indicates no, 1 indicates yes)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_labels = list(labeled_data.keys()) + ['Diagnosis', 'PatientID', 'DoctorInCharge']\n",
    "labels = []\n",
    "for label in data.keys():\n",
    "    if not label in excluded_labels:\n",
    "        labels.append(label)\n",
    "num_labels = len(labels)\n",
    "\n",
    "max_cols = 3\n",
    "num_rows = -(-num_labels // max_cols)\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, max_cols, figsize=(15, num_rows * 5))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, label in enumerate(labels):\n",
    "    alz_indexes = np.where(np.array(data['Diagnosis']) == 1)[0].tolist()\n",
    "    alz_data = []\n",
    "    normal_data = []\n",
    "    for i in range(len(data[label])):\n",
    "        if i in alz_indexes:\n",
    "            alz_data.append(data[label][i])\n",
    "        else:\n",
    "            normal_data.append(data[label][i])\n",
    "\n",
    "    data_comb = [normal_data, alz_data]\n",
    "    axes[idx].hist(data_comb, bins=20, color=['blue', 'orange'], rwidth=0.8, label=[\"Normal\", \"Alzheimer's\"], stacked=True)\n",
    "    axes[idx].axvline(x=np.mean(normal_data), label='Mean for normal', color='skyblue', lw=3, ls='-.')\n",
    "    axes[idx].axvline(x=np.mean(alz_data), label='Mean for Alzheimer\\'s', color='red', lw=3, ls='--')\n",
    "    axes[idx].set_title(label)\n",
    "    axes[idx].legend()\n",
    "    axes[idx].set_xlabel('Value')\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "\n",
    "for idx in range(len(labels), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.955])\n",
    "plt.suptitle('All numerical data columns compared', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these comparisons, we can conclude that there are a few parameters that show different behavior based on the diagnosis.\n",
    "- Categorical:\n",
    "    - `MemoryComplaints` are more common among people with Alzheimer's\n",
    "    - `BehavioralProblems` are more common among people with Alzheimer's\n",
    "    - `EducationLevel` seems to be a little bit lower on average for people with Alzheimer's\n",
    "- Numerical:\n",
    "    - `MMSE` tends to be lower on average for people with Alzheimer's\n",
    "    - `FunctionalAssessment` tends to be lower for people with Alzheimer's\n",
    "    - `ADL` tends to be lower for people with Alzheimer's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations\n",
    "\n",
    "We checked for correlations between numerical variables, using a heatmap.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations between numerical columns\n",
    "\n",
    "df = pd.DataFrame({key: value for key, value in data.items() if key != 'DoctorInCharge'})\n",
    "\n",
    "numerical_variables = ['Age', 'EducationLevel', 'BMI','AlcoholConsumption', 'PhysicalActivity', 'DietQuality',\n",
    "       'SleepQuality', 'SystolicBP',\n",
    "       'DiastolicBP', 'CholesterolTotal', 'CholesterolLDL', 'CholesterolHDL',\n",
    "       'CholesterolTriglycerides', 'MMSE', 'FunctionalAssessment', 'ADL']\n",
    "\n",
    "correlation_matrix = df[numerical_variables].corr()\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate plot of the heatmap \n",
    "mask = np.triu(np.ones_like(df.corr(), dtype=bool))\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df.corr(),cmap=\"coolwarm\", cbar_kws={\"shrink\": .5}, mask=mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We checked if there is a quadratic fit in the data. For example, very low or very high bloop pressure has negative health outcomes - perhaps there are similimar curvilinear relationships with the cholestrol variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_matrix = pd.DataFrame(index=numerical_variables, columns=numerical_variables)\n",
    "\n",
    "# Polynomial feature transformation - quadratic\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "# fit quadratic models and calculate R^2\n",
    "for col1 in numerical_variables:\n",
    "    for col2 in numerical_variables:\n",
    "        if col1 != col2:\n",
    "            X = df[[col1]]\n",
    "            y = df[col2]\n",
    "            X_poly = poly.fit_transform(X)\n",
    "            model = LinearRegression().fit(X_poly, y)\n",
    "            y_pred = model.predict(X_poly)\n",
    "            r2 = r2_score(y, y_pred)\n",
    "            r2_matrix.loc[col1, col2] = r2\n",
    "\n",
    "r2_matrix = r2_matrix.apply(pd.to_numeric)\n",
    "sns.heatmap(r2_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('G.o.F for Quadratic Fits')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No quadratic relationships between any two variables were found. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagnosis rates for different variables, grouped by ethnicity (?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "# LIST OF SIGNIFICANT-LOOKING IVs THAT INTERACT WITH ETHNICITY \n",
    "vars_ethnicity = ['Gender', 'EducationLevel', 'Smoking', 'AlcoholConsumption', 'PhysicalActivity',\n",
    "                  'DietQuality', 'FamilyHistoryAlzheimers', 'CardiovascularDisease', 'Diabetes',\n",
    "                  'Depression', 'HeadInjury', 'Hypertension', 'CholesterolHDL',\n",
    "                  'BehavioralProblems', 'Confusion', 'Disorientation']\n",
    "\n",
    "# LIST OF SIGNIFICANT-LOOKING IVs THAT INTERACT WITH GENDER \n",
    "vars_gender = ['AlcoholConsumption', 'DietQuality', 'FamilyHistoryAlzheimers', 'CardiovascularDisease',\n",
    "               'Depression', 'HeadInjury', 'Hypertension', 'CholesterolTriglycerides','ADL',\n",
    "               'Confusion', 'Disorientation', 'PersonalityChanges']\n",
    "\n",
    "# plotting (EDA)\n",
    "df['Ethnicity'] = df['Ethnicity'].map({0: 'white', 1: 'black', 2: 'asian', 3: 'other'})\n",
    "gender_palette = {0: 'blue', 1: 'pink'}\n",
    "ethnicity_palette = {'white': 'pink', 'black': 'black','asian': 'red','other': 'brown'}\n",
    "\n",
    "def adjust_plot(ax, var, category, labels, palette):\n",
    "    ax.set_title(f'{var} vs Diagnosis by {category}', fontsize=7)\n",
    "    ax.set_ylabel(f'mean {var}')\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['No Diagnosis', 'Diagnosis'], size=7)\n",
    "    handles, _ = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels, title=category, bbox_to_anchor=(1.05, 1), loc='upper left', facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "# ethnicity plots\n",
    "n_cols = 4\n",
    "n_rows = len(vars_ethnicity) // n_cols + (1 if len(vars_ethnicity) % n_cols != 0 else 0)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 3 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(vars_ethnicity):\n",
    "    sns.barplot(x='Diagnosis', y=var, hue='Ethnicity', data=df, ax=axes[i], palette=ethnicity_palette)\n",
    "    adjust_plot(axes[i], var, 'Ethnicity', ['White', 'Black', 'Asian', 'Other'], ethnicity_palette)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# gender plots\n",
    "n_rows = len(vars_gender) // n_cols + (1 if len(vars_gender) % n_cols != 0 else 0)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(13, 2.5 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(vars_gender):\n",
    "    sns.barplot(x='Diagnosis', y=var, hue='Gender', data=df, ax=axes[i], palette=gender_palette)\n",
    "    adjust_plot(axes[i], var, 'Gender', ['Male', 'Female'], gender_palette)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSUMPTION CHECK FOR LOGISTIC REGRESSION \n",
    "\n",
    "'''\n",
    "ASSUMPTIONS OF THE LOGISTIC REGRESSION MODEL\n",
    "\n",
    "1. Binary dependent variable \n",
    "2. No multicollinearity\n",
    "3. Linearity of the logit\n",
    "'''\n",
    "\n",
    "# 1. Binary dependent variable\n",
    "def is_binary(df, target_column):\n",
    "    unique_values = df[target_column].unique()\n",
    "    if len(unique_values) == 2:\n",
    "        return True\n",
    "\n",
    "if is_binary(df, 'Diagnosis'): print(\"binary DV assumption: PASSED\") \n",
    "else : print(\"binary DV assumption: FAILED\")\n",
    "\n",
    "\n",
    "# 2. no multicollinearity (correlations between predictors) \n",
    "''' \n",
    "VIF (Variance Inflation Factor) indicates how much a predictor is influenced by the other predictors by measuring \n",
    "how much the variability of a regression coefficient is increased due to correlation with other predictors. \n",
    "High VIF (>10) suggests that a predictor is highly correlated with others, which can make the model unstable or unreliable.\n",
    "\n",
    "* the import from statsmodels could be replaced by calculating VIF as 1 / 1 - r_squared\n",
    "''' \n",
    "\n",
    "def check_multicollinearity(df, predictor_columns):\n",
    "    corr_matrix = df.corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "    plt.show()\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data['Feature'] = predictor_columns\n",
    "    vif_data['VIF'] = [variance_inflation_factor(df[predictor_columns].values, i) for i in range(len(predictor_columns))]\n",
    "    return corr_matrix, vif_data \n",
    "\n",
    "# can edit this list to include whatever variables we keep in the final analysis\n",
    "predictor_columns = ['DietQuality', 'CholesterolHDL', 'Ethnicity']\n",
    "corr_matrix, vif_data = check_multicollinearity(df, predictor_columns)\n",
    "\n",
    "# No missing values, and correlations < 0.9\n",
    "if corr_matrix.isnull().sum().sum() == 0 and (abs(corr_matrix) < 0.9).all().all():\n",
    "    print(\"Multicollinearity: PASSED\")\n",
    "else: print(\"Multicollinearity: FAILED\")\n",
    "\n",
    "\n",
    "'''\n",
    "The linearity of the logit assumption: each predictor should have a linear relationship with the log odds of the DV.\n",
    "Non-linearity can lead to biased results.\n",
    "'''\n",
    "\n",
    "def check_linearity(df, predictor_columns, DV):\n",
    "\n",
    "    linearity_results = {}\n",
    "\n",
    "    for col in predictor_columns:\n",
    "\n",
    "        X = sm.add_constant(df[col])  \n",
    "        model = sm.Logit(df[DV], X).fit()\n",
    "        linearity_results[col] = model.summary()\n",
    "\n",
    "        # plotting partial residuals\n",
    "        plt.scatter(df[col], model.fittedvalues)\n",
    "        plt.title(f\"Partial residuals for {col}\")\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Fitted values')\n",
    "        plt.show()\n",
    "\n",
    "    return linearity_results\n",
    "\n",
    "linearity_results = check_linearity(df, predictor_columns, 'Diagnosis')\n",
    "for col, result in linearity_results.items():\n",
    "    print(f\" For {col}: Linearity assumption - PASSED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SURVIVAL ANALYSIS \n",
    "\n",
    "'''\n",
    "Survival analysis (via Keplan Meier) callculates the probability of surviving beyond specific time points (here, each age). \n",
    "Here, survival refers to the absence of Alzheimer's. We see how several Risk Factors affect the onset age of Alzheimer's.  \n",
    "For each time point, the function considers the number of individuals who experience the event of interest (Diagnosis=1) and the number still at risk (Diagnosis=0). \n",
    "The survival probability is updated at each time point, it is the proportion of individuals who have 'survived' (stayed healthy) up to that point. \n",
    "'''\n",
    "def kaplan_meier_estimator(df, time_col, event_col, group_col):\n",
    "\n",
    "    '''\n",
    "    This function calculates the Kaplan-Meier survival curves for each category in a categorical variable.\n",
    "    '''\n",
    "\n",
    "    # Create an empty dictionary to store Kaplan-Meier estimates per group\n",
    "    km_data = {}\n",
    "\n",
    "    # loop over each unique value (group) in the categorical variable\n",
    "    for group in df[group_col].unique():\n",
    "\n",
    "        # filter the data for the current group\n",
    "        group_data = df[df[group_col] == group]\n",
    "\n",
    "        # Extract and sort unique time points for this group\n",
    "        times = sorted(group_data[time_col].unique())\n",
    "\n",
    "        # total number of observations in the group\n",
    "        n = len(group_data)\n",
    "\n",
    "        # Initialise an empty list to store the survival probability estimates\n",
    "        km_estimates = []\n",
    "\n",
    "        # Iterate over each unique time point (i.e. each age)\n",
    "        for t in times:\n",
    "\n",
    "            # count the number of events (diagnoses) at the current time point\n",
    "            d = sum((group_data[time_col] == t) & (group_data[event_col] == 1))\n",
    "\n",
    "            # subtract to get those with diagnosis=0\n",
    "            n -= d\n",
    "\n",
    "            # store the survival probability at the current time point\n",
    "            km_estimates.append((t, n / len(group_data)))\n",
    "\n",
    "        # store the Kaplan-Meier estimates for the current group in the aforementioned dictionary\n",
    "        km_data[group] = km_estimates\n",
    "\n",
    "    return km_data\n",
    "\n",
    "\n",
    "'''\n",
    "The log-rank test determines whether survival curves for different groups (e.g. difference races in the variable 'Race') are statistically different. \n",
    "It compares observed and expected event counts at each time point across groups. \n",
    "Expected values are based on the overall event distribution, assuming no group differences. \n",
    "The test aggregates these differences into a chi-square statistic, quantifying how much observed data deviate from the null hypothesis (no difference between groups). \n",
    "'''\n",
    "\n",
    "from scipy.stats import chi2\n",
    "def log_rank_test(df, time_col, event_col, group_col):\n",
    "    '''\n",
    "    this function performs the log-rank test for comparing survival curves\n",
    "    '''\n",
    "    # Get the unique groups and sort the unique event times (ages)\n",
    "    groups = df[group_col].unique()\n",
    "    event_times = df[time_col].unique()\n",
    "    event_times.sort()\n",
    "\n",
    "    # Initialise dictionaries to store observed & expected events and variances (to account for sample size) for each group\n",
    "    observed = {group: [] for group in groups}\n",
    "    expected = {group: [] for group in groups}\n",
    "    var = {group: [] for group in groups}\n",
    "\n",
    "    # loop over each unique event time\n",
    "    for t in event_times:\n",
    "\n",
    "        # Calculate the number of subjects at risk (no diagnosis) at the current time point for each group\n",
    "        at_risk = {group: len(df[(df[time_col] >= t) & (df[group_col] == group)]) for group in groups}\n",
    "\n",
    "        # Calculate the number of events (diagnoses) at the current time point for each group\n",
    "        events = {group: len(df[(df[time_col] == t) & (df[event_col] == 1) & (df[group_col] == group)]) for group in groups}\n",
    "       \n",
    "        # total the above \n",
    "        total_at_risk = sum(at_risk.values())\n",
    "        total_events = sum(events.values())\n",
    "\n",
    "        # loop over each group to calculate observed, expected, and variance\n",
    "        for group in groups:\n",
    "\n",
    "            # observed events for the current group and time point\n",
    "            observed[group].append(events[group])\n",
    "\n",
    "            # expected number of events\n",
    "            expected[group].append(at_risk[group] * total_events / total_at_risk)\n",
    "\n",
    "            # variance for the current group\n",
    "            var[group].append(at_risk[group] * (total_at_risk - at_risk[group]) * total_events * (total_at_risk - total_events) / (total_at_risk ** 2 * (total_at_risk - 1)))\n",
    "\n",
    "    # Sum up observed, expected, and variance values for each group\n",
    "    observed = {group: np.sum(observed[group]) for group in groups}\n",
    "    expected = {group: np.sum(expected[group]) for group in groups}\n",
    "    var = {group: np.sum(var[group]) for group in groups}\n",
    "\n",
    "    # chi-square statistic and p value \n",
    "    chi_square = np.sum([(observed[group] - expected[group]) ** 2 / var[group] for group in groups])\n",
    "    p = chi2.sf(chi_square, df=len(groups) - 1)\n",
    "\n",
    "    return chi_square, p\n",
    "\n",
    "def plot_kaplan_meier(df, time_col, event_col, group_col, ax):\n",
    "\n",
    "    # Compute Kaplan-Meier estimates for each group\n",
    "    km_data = kaplan_meier_estimator(df, time_col, event_col, group_col)\n",
    "    # Perform the log-rank test to compare survival curves\n",
    "    chi_square, p = log_rank_test(df, time_col, event_col, group_col)\n",
    "    \n",
    "    # Plot Kaplan-Meier curves for each group\n",
    "    for group in km_data:\n",
    "\n",
    "        # Extract time points and survival probabilities for the current group\n",
    "        times, estimates = zip(*km_data[group])\n",
    "\n",
    "        # Plot the step function representing the Kaplan-Meier curve\n",
    "        ax.step(times, estimates, where='post', label=f'{group_col} {group}')\n",
    "\n",
    "    ax.set_xlabel('Age')\n",
    "    ax.set_ylabel('Survival Probability')\n",
    "    ax.set_title(f'Kaplan-Meier survival curves: {group_col} \\n p={p:.3f}')\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'MemoryComplaints', axes[0])\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'BehavioralProblems', axes[1])\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'Disorientation', axes[2])\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'CardiovascularDisease', axes[3])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'FamilyHistoryAlzheimers', axes[0])\n",
    "axes[0].text(0.4, 0.2, 'Surprisingly non-significant', transform=axes[0].transAxes, ha='center', va='center', fontsize=10, color='red', fontweight='bold')\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'Hypertension', axes[1])\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'DifficultyCompletingTasks', axes[2])\n",
    "axes[2].text(0.4, 0.2, 'Surprisingly non-significant', transform=axes[2].transAxes, ha='center', va='center', fontsize=10, color='red', fontweight='bold')\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'Forgetfulness', axes[3])\n",
    "axes[3].text(0.4, 0.2, 'Surprisingly non-significant', transform=axes[3].transAxes, ha='center', va='center', fontsize=10, color='red', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print('continuous variables, manually categorised:')\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n",
    "\n",
    "# BMI \n",
    "df['BMI_Category'] = pd.cut(df['BMI'], bins=[0, 18.5, 25, 30, np.inf], labels=['Underweight', 'Normal', 'Overweight', 'Obesity'], right=False)\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'BMI_Category', axes[0])\n",
    "\n",
    "# ALCOHOL \n",
    "# not robust - non-significant with 2 or 4 categories \n",
    "df['AlcoholCategory'] = pd.qcut(df['AlcoholConsumption'], q=[0, 0.25, 0.75, 1.0], labels=['Low', 'Medium', 'High'])\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'AlcoholCategory', axes[1])\n",
    "axes[1].text(0.42, 0.1, 'not robust, non-sig with 2 or 4 categories', transform=axes[1].transAxes, ha='center', va='center', fontsize=9, color='red')\n",
    "\n",
    "# ADL (acitivities of daily living e.g. self-grooming, feeding oneself)\n",
    "df['ADL_Category'] = pd.cut(df['ADL'], bins=[0, 3, 6, 9, 10], labels=['Low', 'Moderate', 'High', 'Very High'], include_lowest=True)\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'ADL_Category', axes[2])\n",
    "\n",
    "# SLEEP QUALITY\n",
    "df['sleep_quality'] = pd.cut(df['SleepQuality'], bins=[0, 5, 7, 9, np.inf], labels=['Poor', 'Fair', 'Good', 'Excellent'], right=False)\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'sleep_quality', axes[3])\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 3))\n",
    "# MMSE\n",
    "df['MMSE_cat'] = pd.cut(df['MMSE'], bins=[0, 10, 20, 30], labels=['Severe Cognitive Impairment', 'Mild Cognitive Impairment', 'Normal'], right=False)\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'MMSE_cat', axes[0])\n",
    "\n",
    "# Cholesterol HDL\n",
    "df['Cholesterol HDL'] = pd.cut(df['CholesterolHDL'], bins=[0, 40, 60, np.inf], labels=['Low', 'Normal', 'High'], right=False)\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'Cholesterol HDL', axes[1])\n",
    "\n",
    "# Cholesterol LDL\n",
    "df['Cholesterol LDL'] = pd.cut(df['CholesterolLDL'], bins=[0, 100, 200], labels=['Optimal', 'High'], right=False)\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'Cholesterol LDL', axes[2])\n",
    "\n",
    "print()\n",
    "\n",
    "# COMPOSITE SCORES\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n",
    "\n",
    "df['MentalHealthScore'] = (df['Depression'] + df['BehavioralProblems'] + df['Confusion'] + df['Disorientation']) / 4\n",
    "df['MentalHealthScore'] = (df['MentalHealthScore'] - df['MentalHealthScore'].min()) / (df['MentalHealthScore'].max() - df['MentalHealthScore'].min())                     \n",
    "df['MentalHealthCategory'] = pd.cut(df['MentalHealthScore'], bins=[-0.01, 0.33, 0.66, 1.01], labels=['good mental health', 'moderate', 'poor'])\n",
    "\n",
    "df['MetabolicRiskScore'] = (df['BMI'] + df['CholesterolTotal'] + df['CholesterolTriglycerides'] + df['SystolicBP'] + df['DiastolicBP']) / 5                                                \n",
    "df['MetabolicRiskScore'] = (df['MetabolicRiskScore'] - df['MetabolicRiskScore'].min()) / (df['MetabolicRiskScore'].max() - df['MetabolicRiskScore'].min())                \n",
    "df['MetabolicRiskCategory'] = pd.cut(df['MetabolicRiskScore'], bins=[-0.01, 0.33, 0.66, 1.01], labels=['Low', 'Moderate', 'High']) \n",
    "\n",
    "df['FunctioningScore'] = (df['ADL'] + df['DifficultyCompletingTasks'] + df['Forgetfulness'] + df['Disorientation']) / 4\n",
    "df['FunctioningScore'] = (df['FunctioningScore'] - df['FunctioningScore'].min()) / (df['FunctioningScore'].max() - df['FunctioningScore'].min())\n",
    "df['FunctioningCategory'] = pd.cut(df['FunctioningScore'], bins=[-0.01, 0.33, 0.66, 1.01], labels=['impaired', 'Moderate', 'independent'])\n",
    "\n",
    "df['CognitiveHealthScore'] = (df['MMSE'] + df['FunctionalAssessment'] + df['MemoryComplaints']) / 3\n",
    "df['CognitiveHealthScore'] = (df['CognitiveHealthScore'] - df['CognitiveHealthScore'].min()) / (df['CognitiveHealthScore'].max() - df['CognitiveHealthScore'].min())\n",
    "df['CognitiveHealthCategory'] = pd.cut(df['CognitiveHealthScore'], bins=[-float('inf'), 0.33, 0.66, float('inf')], labels=['Low', 'Moderate', 'High'])\n",
    "\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'MentalHealthCategory', axes[0])\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'MetabolicRiskCategory', axes[1])\n",
    "axes[1].text(0.42, 0.1, 'curvilinear variables!', transform=axes[1].transAxes, ha='center', va='center', fontsize=9, color='red')\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'FunctioningCategory', axes[2])\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'CognitiveHealthCategory', axes[3])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'MemoryComplaints', axes[0])\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'BehavioralProblems', axes[1])\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'Disorientation', axes[2])\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'CardiovascularDisease', axes[3])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'FamilyHistoryAlzheimers', axes[0])\n",
    "axes[0].text(0.4, 0.2, 'Surprisingly non-significant', transform=axes[0].transAxes, ha='center', va='center', fontsize=10, color='red', fontweight='bold')\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'Hypertension', axes[1])\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'DifficultyCompletingTasks', axes[2])\n",
    "axes[2].text(0.4, 0.2, 'Surprisingly non-significant', transform=axes[2].transAxes, ha='center', va='center', fontsize=10, color='red', fontweight='bold')\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'Forgetfulness', axes[3])\n",
    "axes[3].text(0.4, 0.2, 'Surprisingly non-significant', transform=axes[3].transAxes, ha='center', va='center', fontsize=10, color='red', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print('continuous variables, manually categorised:')\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n",
    "\n",
    "# BMI\n",
    "df['BMI_Category'] = pd.cut(df['BMI'], bins=[0, 18.5, 25, 30, np.inf], labels=['Underweight', 'Normal', 'Overweight', 'Obesity'], right=False)\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'BMI_Category', axes[0])\n",
    "\n",
    "# ALCOHOL\n",
    "# not robust - non-significant with 2 or 4 categories \n",
    "df['AlcoholCategory'] = pd.qcut(df['AlcoholConsumption'], q=[0, 0.25, 0.75, 1.0], labels=['Low', 'Medium', 'High'])\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'AlcoholCategory', axes[1])\n",
    "axes[1].text(0.42, 0.1, 'not robust, non-sig with 2 or 4 categories', transform=axes[1].transAxes, ha='center', va='center', fontsize=9, color='red')\n",
    "\n",
    "# ADL (acitivities of daily living e.g. self-grooming, feeding oneself)\n",
    "df['ADL_Category'] = pd.cut(df['ADL'], bins=[0, 3, 6, 9, 10], labels=['Low', 'Moderate', 'High', 'Very High'], include_lowest=True)\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'ADL_Category', axes[2])\n",
    "\n",
    "# SLEEP QUALITY\n",
    "df['sleep_quality'] = pd.cut(df['SleepQuality'], bins=[0, 5, 7, 9, np.inf], labels=['Poor', 'Fair', 'Good', 'Excellent'], right=False)\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'sleep_quality', axes[3])\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 3))\n",
    "# MMSE\n",
    "df['MMSE_cat'] = pd.cut(df['MMSE'], bins=[0, 10, 20, 30], labels=['Severe Cognitive Impairment', 'Mild Cognitive Impairment', 'Normal'], right=False)\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'MMSE_cat', axes[0])\n",
    "\n",
    "# Cholesterol HDL\n",
    "df['Cholesterol HDL'] = pd.cut(df['CholesterolHDL'], bins=[0, 40, 60, np.inf], labels=['Low', 'Normal', 'High'], right=False)\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'Cholesterol HDL', axes[1])\n",
    "\n",
    "# Cholesterol LDL\n",
    "df['Cholesterol LDL'] = pd.cut(df['CholesterolLDL'], bins=[0, 100, 200], labels=['Optimal', 'High'], right=False)\n",
    "plot_kaplan_meier(df, 'Age', 'Diagnosis', 'Cholesterol LDL', axes[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the feature sets\n",
    "biological_features = [\n",
    "    'Age', 'Ethnicity', 'Gender', 'BMI', 'FamilyHistoryAlzheimers',\n",
    "    'CardiovascularDisease', 'Diabetes', 'Hypertension',\n",
    "    'SystolicBP', 'DiastolicBP', 'CholesterolTotal',\n",
    "    'CholesterolLDL', 'CholesterolHDL', 'CholesterolTriglycerides']\n",
    "\n",
    "cognitive_features = [\n",
    "    'MMSE', 'FunctionalAssessment', 'MemoryComplaints',\n",
    "    'BehavioralProblems', 'ADL', 'Confusion', 'Disorientation',\n",
    "    'PersonalityChanges', 'DifficultyCompletingTasks', 'Forgetfulness']\n",
    "\n",
    "lifestyle_features = [\n",
    "    'Smoking', 'AlcoholConsumption', 'PhysicalActivity',\n",
    "    'DietQuality', 'SleepQuality', 'Depression', 'HeadInjury',\n",
    "    'EducationLevel']\n",
    "\n",
    "feature_sets = {'Biological Features': biological_features, 'Cognitive Features': cognitive_features,'Lifestyle Features': lifestyle_features}\n",
    "\n",
    "\n",
    "# Loop through each feature set\n",
    "for feature_set_name, features in feature_sets.items():\n",
    "    print(f\"\\nUsing {feature_set_name}:\")\n",
    "    \n",
    "    X = df[features]  # Input features\n",
    "    y = df['Diagnosis']  # Target label\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "    # Decision Tree Classifier\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "        \n",
    "    # simplify the tree with entropy criterion\n",
    "    model_entropy = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "    model_entropy.fit(X_train, y_train)\n",
    "    y_pred_entropy = model_entropy.predict(X_test)\n",
    "    entropy_accuracy = accuracy_score(y_test, y_pred_entropy)\n",
    "    print(f\"Entropy-Based Tree Accuracy: {entropy_accuracy:.2f}\")\n",
    "\n",
    "    # Visualize the simpler tree\n",
    "    plt.figure(figsize=(18, 12))\n",
    "    plot_tree(\n",
    "        model_entropy, \n",
    "        feature_names=features, \n",
    "        class_names=['No Diagnosis', 'Diagnosis'], \n",
    "        filled=True, \n",
    "        rounded=True, \n",
    "        fontsize=10,\n",
    "        proportion=True\n",
    "    )\n",
    "    ax = plt.gca()  \n",
    "    for arrow in ax.patches:\n",
    "        arrow.set_linewidth(0.55)  \n",
    "\n",
    "    plt.title(f\"Decision Tree Visualization for {feature_set_name}\\nModel Accuracy: {accuracy_score(y_test, y_pred_entropy):.2f}\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
