{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Using clustering, we may be able to find particular clusters of patients that have a higher amount of Alzheimer's disease than others. Then, based on the differences between clusters, we might be able to find a pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_reader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def dissimilarity_score(v1, v2):\n",
    "    # For categorical variables, calculating the euclidian distance is not\n",
    "    # correct. Therefore, the amount of differences should just be counted.\n",
    "    return np.sum(v1 != v2)\n",
    "\n",
    "\n",
    "def euclidian_distance(v1, v2):\n",
    "    return np.sqrt(np.sum((v1 - v2)**2))\n",
    "\n",
    "\n",
    "def assign_cluster(prototypes, clusters, point):\n",
    "    dissimilarities = []\n",
    "    for pt in prototypes:\n",
    "        v_n = num_matrix[point]\n",
    "        v_c = cat_matrix[point]\n",
    "        pt_v_n = pt[0]\n",
    "        pt_v_c = pt[1]\n",
    "        dissimilarity = dissimilarity_score(\n",
    "            pt_v_n, v_n) + euclidian_distance(pt_v_c, v_c)\n",
    "        dissimilarities.append(dissimilarity)\n",
    "\n",
    "    dissimilarities = np.array(dissimilarities)\n",
    "    cluster = np.where(dissimilarities == dissimilarities.min())[0][0]\n",
    "    clusters[cluster].append((num_matrix[point], cat_matrix[point]))\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def calc_prototype(cluster, init_index):\n",
    "    if len(cluster) == 0:\n",
    "        # Whenever a cluster is empty, reset the prototype to what the prototype\n",
    "        # originally was for this cluster. Taking the means/modes of all variables\n",
    "        # or setting it to 0 did not work well, as it would result in lots of\n",
    "        # empty clusters.\n",
    "        return (num_matrix[init_index], cat_matrix[init_index])\n",
    "    num_cluster = np.vstack([point[0] for point in cluster])\n",
    "    num_prototype = np.mean(num_cluster, axis=0)\n",
    "    cat_cluster = np.vstack([point[1] for point in cluster])\n",
    "    cat_prototype = mode(cat_cluster, axis=0).mode\n",
    "\n",
    "    return (num_prototype, cat_prototype)\n",
    "\n",
    "\n",
    "def k_prototypes_clustering(num_matrix, cat_matrix, k, verbose=False, initial_prototypes=None):\n",
    "    if initial_prototypes is None:\n",
    "        # Randomly select k initial prototype indexes\n",
    "        prototypes_indices = np.random.randint(0, len(num_matrix), k)\n",
    "        init_indexes = prototypes_indices.copy()\n",
    "        if verbose:\n",
    "            print(f'Selected initial prototypes indices: {prototypes_indices}')\n",
    "\n",
    "        # Initialize prototypes as a list of tuples with numeric and categorical data\n",
    "        prototypes = [(num_matrix[i], cat_matrix[i])\n",
    "                      for i in prototypes_indices]\n",
    "    else:\n",
    "        init_indexes = initial_prototypes.copy()\n",
    "        if len(initial_prototypes) != k:\n",
    "            raise ValueError(\"The number of initial prototypes must match k.\")\n",
    "        prototypes = [(num_matrix[i], cat_matrix[i])\n",
    "                      for i in initial_prototypes]\n",
    "\n",
    "    clusters = [[] for _ in range(k)]\n",
    "\n",
    "    while True:\n",
    "        for i in range(len(num_matrix)):\n",
    "            clusters = assign_cluster(prototypes, clusters, i)\n",
    "\n",
    "        new_prototypes = [calc_prototype(clusters[i], init_indexes[i]) for i in range(len(clusters))]\n",
    "\n",
    "        # Check for convergence, meaning that the prototypes did not change\n",
    "        # during the current iteration, indicating that the algorithm is done.\n",
    "        done = True\n",
    "        for i in range(len(prototypes)):\n",
    "            if not np.array_equal(prototypes[i][0], new_prototypes[i][0]) or \\\n",
    "               not np.array_equal(prototypes[i][1], new_prototypes[i][1]):\n",
    "                done = False\n",
    "                break\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        prototypes = new_prototypes\n",
    "        clusters = [[] for _ in range(k)]\n",
    "\n",
    "    if verbose:\n",
    "        print(f'--- {k} clusters found ---')\n",
    "        for i, cluster in enumerate(clusters):\n",
    "            print(f' - Cluster {i + 1} with size={len(cluster)}')\n",
    "\n",
    "    return clusters, prototypes, prototypes_indices\n",
    "\n",
    "\n",
    "data = data_reader.get_data_dict('./data/alzheimers_disease_data.csv')\n",
    "\n",
    "# Numerical columns\n",
    "num_cols = ['BMI', 'SystolicBP', 'DiastolicBP', 'CholesterolTotal', 'CholesterolLDL',\n",
    "            'CholesterolHDL', 'CholesterolTriglycerides', 'MMSE', 'FunctionalAssessment',\n",
    "            'AlcoholConsumption', 'PhysicalActivity', 'DietQuality', 'SleepQuality',\n",
    "            'ADL']\n",
    "# Categorical columns\n",
    "cat_cols = ['FamilyHistoryAlzheimers', 'CardiovascularDisease', 'Diabetes',\n",
    "            'Depression', 'Hypertension', 'MemoryComplaints', 'BehavioralProblems',\n",
    "            'Confusion', 'Disorientation', 'PersonalityChanges', 'DifficultyCompletingTasks',\n",
    "            'Forgetfulness', 'HeadInjury', 'Smoking', 'Ethnicity', 'Gender',\n",
    "            'EducationLevel', 'Diagnosis']\n",
    "\n",
    "num_matrix = np.vstack(tuple(data[col] for col in num_cols)).T\n",
    "cat_matrix = np.vstack(tuple(data[col] for col in cat_cols)).T\n",
    "\n",
    "clusters, prototypes, _ = k_prototypes_clustering(num_matrix, cat_matrix, 5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try to find the best starting prototypes, based on which of them creates clusters with the least total distance between the points and their cluster centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 50\n",
    "k = 4\n",
    "\n",
    "best_clusters = None\n",
    "best_prototypes = None\n",
    "best_score = float('inf')\n",
    "best_prototype_index = None\n",
    "\n",
    "# Perform multiple runs to find which initial prototypes produce the smallest\n",
    "# total difference, which is then marked as the best.\n",
    "for run in range(num_runs):\n",
    "    clusters = [[] for _ in range(k)]\n",
    "\n",
    "    clusters, prototypes, prototype_index = k_prototypes_clustering(num_matrix, cat_matrix, k)\n",
    "\n",
    "    total_distance = 0\n",
    "    for cluster_idx, cluster in enumerate(clusters):\n",
    "        for point in cluster:\n",
    "            num_distance = euclidian_distance(point[0], prototypes[cluster_idx][0])\n",
    "            cat_distance = dissimilarity_score(point[1], prototypes[cluster_idx][1])\n",
    "            total_distance += num_distance + cat_distance\n",
    "\n",
    "    if total_distance < best_score:\n",
    "        best_score = total_distance\n",
    "        best_clusters = clusters\n",
    "        best_prototypes = prototypes\n",
    "        best_prototype_index = prototype_index\n",
    "\n",
    "print(f\"Best clustering result found after {num_runs} runs:\")\n",
    "print(f\"Within-cluster distance: {best_score:.2f}\")\n",
    "for i, cluster in enumerate(best_clusters):\n",
    "    print(f\"Cluster {i + 1}: {len(cluster)} points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_prototype_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "cluster_data = [point[0] for cluster in best_clusters for point in cluster]\n",
    "cluster_labels = [i for i, cluster in enumerate(best_clusters) for _ in cluster]\n",
    "\n",
    "reduced_data = pca.fit_transform(cluster_data)\n",
    "plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=cluster_labels, cmap='tab10')\n",
    "plt.title(\"Cluster Visualization\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.colorbar(label=\"Cluster\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproduce results by using the found best indexes.\n",
    "prototypes = best_prototype_index\n",
    "prototypes = [(num_matrix[i], cat_matrix[i]) for i in prototypes]\n",
    "\n",
    "clusters, prototypes, prototype_index = k_prototypes_clustering(num_matrix, cat_matrix, k)\n",
    "\n",
    "print(\"Reproduced clustering result:\")\n",
    "for i, cluster in enumerate(clusters):\n",
    "    print(f\"Cluster {i + 1}: {len(cluster)} points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "cluster_data = [point[0] for cluster in clusters for point in cluster]\n",
    "cluster_labels = [i for i, cluster in enumerate(clusters) for _ in cluster]\n",
    "\n",
    "reduced_data = pca.fit_transform(cluster_data)\n",
    "plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=cluster_labels)\n",
    "plt.title(\"Cluster Visualization\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.colorbar(label=\"Cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither of the clustering visualisations show anything that resembles clusters, which can be explained by the fact that the clusters are made up of many more components than just these two. To find if there are any differences, we can try to use the mean and modes of these different components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "modes = []\n",
    "ratios = []\n",
    "for cluster in clusters:\n",
    "    cluster_num_matrix = np.array([item[0] for item in cluster])\n",
    "    cluster_cat_matrix = np.array([item[1] for item in cluster])\n",
    "    diagnosis = cluster_cat_matrix[:, -1]\n",
    "    count_zeros = np.sum(diagnosis == 0)\n",
    "    count_ones = np.sum(diagnosis == 1)\n",
    "    ratios.append(count_ones/(count_zeros + count_ones))\n",
    "    cluster_means = np.mean(cluster_num_matrix, axis=0)\n",
    "    cluster_modes = mode(cluster_cat_matrix, axis=0).mode\n",
    "    means.append(cluster_means)\n",
    "    modes.append(cluster_modes)\n",
    "\n",
    "\n",
    "print('-- Ratios of diagnosis --')\n",
    "print(ratios)\n",
    "\n",
    "print('-- Numerical Columns means --')\n",
    "for i in range(len(num_cols)):\n",
    "    print(num_cols[i])\n",
    "    print([mean[i] for mean in means])\n",
    "\n",
    "print('-- Categorical Columns modes --')\n",
    "for i in range(len(cat_cols)):\n",
    "    print(cat_cols[i])\n",
    "    print([mode[i] for mode in modes])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there are no significant differences between the clusters. Sometimes, the clustering algorithm returns clusters where the diagnoses are spread evenly (about 33% of patients have one per cluster). Even when the algorithm returns clusters where there are some with (close to) 0 diagnoses and others where (close to) everyone has a diagnosis, we still cannot find any differences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
