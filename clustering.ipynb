{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Using clustering, we may be able to find particular clusters of patients that have a higher amount of Alzheimer's disease than others. Then, based on the differences between clusters, we might be able to find a pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected initial prototypes: [1233 1862  564  962  485]\n",
      "---  5 clusters found  ---\n",
      " - Cluster 1 with size=232\n",
      " - Cluster 2 with size=351\n",
      " - Cluster 3 with size=185\n",
      " - Cluster 4 with size=962\n",
      " - Cluster 5 with size=419\n"
     ]
    }
   ],
   "source": [
    "import data_reader\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Select k datapoints at random using the PatientID\n",
    "data = data_reader.get_data_dict('./data/alzheimers_disease_data.csv')\n",
    "columns = list(data.keys())\n",
    "\n",
    "# Create a matrix for numerical and for categorical data\n",
    "num_cols = ['BMI', 'SystolicBP', 'DiastolicBP', 'CholesterolTotal', 'CholesterolLDL',\n",
    "    'CholesterolHDL', 'CholesterolTriglycerides', 'MMSE', 'FunctionalAssessment',\n",
    "    'AlcoholConsumption', 'PhysicalActivity', 'DietQuality', 'SleepQuality',\n",
    "    'ADL']\n",
    "cat_cols = ['FamilyHistoryAlzheimers', 'CardiovascularDisease', 'Diabetes',\n",
    "      'Depression', 'Hypertension', 'MemoryComplaints', 'BehavioralProblems',\n",
    "      'Confusion', 'Disorientation', 'PersonalityChanges', 'DifficultyCompletingTasks',\n",
    "      'Forgetfulness', 'HeadInjury', 'Smoking', 'Ethnicity', 'Gender',\n",
    "      'EducationLevel']\n",
    "\n",
    "num_matrix = np.vstack(tuple(data[col] for col in num_cols)).T\n",
    "cat_matrix = np.vstack(tuple(data[col] for col in cat_cols)).T\n",
    "\n",
    "# Set k to the desired amount of clusters\n",
    "k = 5\n",
    "prototypes = np.random.randint(0, len(num_matrix), k)\n",
    "print(f'Selected initial prototypes: {prototypes}')\n",
    "\n",
    "# From now on, we keep track of prototypes in the following way. Only the first\n",
    "# prototypes will be actual datapoints, while the later prototypes will simply\n",
    "# contain the means and modes of the data in a cluster.\n",
    "prototypes = [(num_matrix[i], cat_matrix[i]) for i in prototypes]\n",
    "clusters = []\n",
    "for _ in range(k):\n",
    "    clusters.append([])\n",
    "\n",
    "\n",
    "def dissimilarity_score(v1, v2):\n",
    "    # Calculate the amount of differences between categorical features\n",
    "    differences = v1 != v2\n",
    "    return np.sum(differences)\n",
    "\n",
    "\n",
    "def euclidian_distance(v1, v2):\n",
    "    # Calculate the euclidian distance between numerical features\n",
    "    return np.sqrt(np.sum((v1 - v2)**2))\n",
    "\n",
    "\n",
    "def assign_cluster(prototypes, clusters, point):\n",
    "    dissimilarities = []\n",
    "    for pt in prototypes:\n",
    "        v_n = num_matrix[point]\n",
    "        v_c = cat_matrix[point]\n",
    "        pt_v_n = pt[0]\n",
    "        pt_v_c = pt[1]\n",
    "        dissimilarity = dissimilarity_score(pt_v_n, v_n) + euclidian_distance(pt_v_c, v_c)\n",
    "        dissimilarities.append(dissimilarity)\n",
    "\n",
    "    dissimilarities = np.array(dissimilarities)\n",
    "    cluster = np.where(dissimilarities == dissimilarities.min())[0][0]\n",
    "    clusters[cluster].append((num_matrix[point], cat_matrix[point]))\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def calc_prototype(cluster):\n",
    "    # Calculate a new prototype\n",
    "    num_cluster = np.vstack([point[0] for point in cluster])\n",
    "    num_prototype = np.mean(num_cluster, axis=0)\n",
    "    cat_cluster = np.vstack([point[1] for point in cluster])\n",
    "    cat_prototype = mode(cat_cluster, axis=0).mode\n",
    "\n",
    "    return (num_prototype, cat_prototype)\n",
    "\n",
    "\n",
    "# For each datapoint, calculate its dissimilarity with each prototype and assign\n",
    "# it to the cluster that corresponds to the prototype with the smallest\n",
    "# dissimilarity\n",
    "while True:\n",
    "    for i in range(len(num_matrix)):\n",
    "        clusters = assign_cluster(prototypes, clusters, i)\n",
    "    # calculate new prototypes\n",
    "    new_prototypes = []\n",
    "    for cluster in clusters:\n",
    "        new_prototypes.append(calc_prototype(cluster))\n",
    "\n",
    "    done = True\n",
    "    for i in range(len(prototypes)):\n",
    "        if not np.array_equal(prototypes[i][0], new_prototypes[i][0]) or \\\n",
    "            not np.array_equal(prototypes[i][1], new_prototypes[i][1]):\n",
    "            done = False\n",
    "            break\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "    prototypes = new_prototypes\n",
    "\n",
    "    clusters = []\n",
    "    for i in range(k):\n",
    "        clusters.append([])\n",
    "\n",
    "\n",
    "print(f'---  {k} clusters found  ---')\n",
    "for i in range(len(clusters)):\n",
    "    print(f' - Cluster {i + 1} with size={len(clusters[i])}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
