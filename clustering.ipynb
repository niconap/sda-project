{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Using clustering, we may be able to find particular clusters of patients that have a higher amount of Alzheimer's disease than others. Then, based on the differences between clusters, we might be able to find a pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_reader\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Select k datapoints at random using the PatientID\n",
    "data = data_reader.get_data_dict('./data/alzheimers_disease_data.csv')\n",
    "data = {k.strip(): v for k, v in data.items()}\n",
    "columns = list(data.keys())\n",
    "\n",
    "# Create a matrix for numerical and for categorical data\n",
    "num_cols = ['BMI', 'SystolicBP', 'DiastolicBP', 'CholesterolTotal', 'CholesterolLDL',\n",
    "    'CholesterolHDL', 'CholesterolTriglycerides', 'MMSE', 'FunctionalAssessment',\n",
    "    'AlcoholConsumption', 'PhysicalActivity', 'DietQuality', 'SleepQuality',\n",
    "    'ADL']\n",
    "cat_cols = ['FamilyHistoryAlzheimers', 'CardiovascularDisease', 'Diabetes',\n",
    "      'Depression', 'Hypertension', 'MemoryComplaints', 'BehavioralProblems',\n",
    "      'Confusion', 'Disorientation', 'PersonalityChanges', 'DifficultyCompletingTasks',\n",
    "      'Forgetfulness', 'HeadInjury', 'Smoking', 'Ethnicity', 'Gender',\n",
    "      'EducationLevel']\n",
    "\n",
    "num_matrix = np.vstack(tuple(data[col] for col in num_cols)).T\n",
    "cat_matrix = np.vstack(tuple(data[col] for col in cat_cols)).T\n",
    "\n",
    "# Set k to the desired amount of clusters\n",
    "k = 5\n",
    "prototypes = np.random.randint(0, len(num_matrix), k)\n",
    "print(f'Selected initial prototypes: {prototypes}')\n",
    "\n",
    "# From now on, we keep track of prototypes in the following way. Only the first\n",
    "# prototypes will be actual datapoints, while the later prototypes will simply\n",
    "# contain the means and modes of the data in a cluster.\n",
    "prototypes = [(num_matrix[i], cat_matrix[i]) for i in prototypes]\n",
    "clusters = []\n",
    "for _ in range(k):\n",
    "    clusters.append([])\n",
    "\n",
    "\n",
    "def dissimilarity_score(v1, v2):\n",
    "    # Calculate the amount of differences between categorical features\n",
    "    differences = v1 != v2\n",
    "    return np.sum(differences)\n",
    "\n",
    "\n",
    "def euclidian_distance(v1, v2):\n",
    "    # Calculate the euclidian distance between numerical features\n",
    "    return np.sqrt(np.sum((v1 - v2)**2))\n",
    "\n",
    "\n",
    "def assign_cluster(prototypes, clusters, point):\n",
    "    dissimilarities = []\n",
    "    for pt in prototypes:\n",
    "        v_n = num_matrix[point]\n",
    "        v_c = cat_matrix[point]\n",
    "        pt_v_n = pt[0]\n",
    "        pt_v_c = pt[1]\n",
    "        dissimilarity = dissimilarity_score(pt_v_n, v_n) + euclidian_distance(pt_v_c, v_c)\n",
    "        dissimilarities.append(dissimilarity)\n",
    "\n",
    "    dissimilarities = np.array(dissimilarities)\n",
    "    cluster = np.where(dissimilarities == dissimilarities.min())[0][0]\n",
    "    clusters[cluster].append((num_matrix[point], cat_matrix[point]))\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def calc_prototype(cluster):\n",
    "    # Calculate a new prototype\n",
    "    num_cluster = np.vstack([point[0] for point in cluster])\n",
    "    num_prototype = np.mean(num_cluster, axis=0)\n",
    "    cat_cluster = np.vstack([point[1] for point in cluster])\n",
    "    cat_prototype = mode(cat_cluster, axis=0).mode\n",
    "\n",
    "    return (num_prototype, cat_prototype)\n",
    "\n",
    "\n",
    "# For each datapoint, calculate its dissimilarity with each prototype and assign\n",
    "# it to the cluster that corresponds to the prototype with the smallest\n",
    "# dissimilarity\n",
    "while True:\n",
    "    for i in range(len(num_matrix)):\n",
    "        clusters = assign_cluster(prototypes, clusters, i)\n",
    "    # calculate new prototypes\n",
    "    new_prototypes = []\n",
    "    for cluster in clusters:\n",
    "        new_prototypes.append(calc_prototype(cluster))\n",
    "\n",
    "    done = True\n",
    "    for i in range(len(prototypes)):\n",
    "        if not np.array_equal(prototypes[i][0], new_prototypes[i][0]) or \\\n",
    "            not np.array_equal(prototypes[i][1], new_prototypes[i][1]):\n",
    "            done = False\n",
    "            break\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "    prototypes = new_prototypes\n",
    "\n",
    "    clusters = []\n",
    "    for i in range(k):\n",
    "        clusters.append([])\n",
    "\n",
    "\n",
    "print(f'---  {k} clusters found  ---')\n",
    "for i in range(len(clusters)):\n",
    "    print(f' - Cluster {i + 1} with size={len(clusters[i])}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_reader\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Load data and prepare matrices\n",
    "# Load data from the Alzheimer's dataset\n",
    "# Assume column names might have trailing spaces, so strip them\n",
    "raw_data = data_reader.get_data_dict('./data/alzheimers_disease_data.csv')\n",
    "data = {key.strip(): value for key, value in raw_data.items()}\n",
    "\n",
    "# Define numerical and categorical columns\n",
    "num_cols = ['BMI', 'SystolicBP', 'DiastolicBP', 'CholesterolTotal', 'CholesterolLDL',\n",
    "    'CholesterolHDL', 'CholesterolTriglycerides', 'MMSE', 'FunctionalAssessment',\n",
    "    'AlcoholConsumption', 'PhysicalActivity', 'DietQuality', 'SleepQuality',\n",
    "    'ADL']\n",
    "cat_cols = ['FamilyHistoryAlzheimers', 'CardiovascularDisease', 'Diabetes',\n",
    "      'Depression', 'Hypertension', 'MemoryComplaints', 'BehavioralProblems',\n",
    "      'Confusion', 'Disorientation', 'PersonalityChanges', 'DifficultyCompletingTasks',\n",
    "      'Forgetfulness', 'HeadInjury', 'Smoking', 'Ethnicity', 'Gender',\n",
    "      'EducationLevel']\n",
    "\n",
    "# Create matrices for numerical and categorical data\n",
    "num_matrix = np.vstack(tuple(data[col] for col in num_cols)).T\n",
    "cat_matrix = np.vstack(tuple(data[col] for col in cat_cols)).T\n",
    "\n",
    "# Dissimilarity and distance functions\n",
    "def dissimilarity_score(v1, v2):\n",
    "    return np.sum(v1 != v2)\n",
    "\n",
    "def euclidian_distance(v1, v2):\n",
    "    return np.sqrt(np.sum((v1 - v2)**2))\n",
    "\n",
    "# Initialize variables\n",
    "k = 5  # Number of clusters\n",
    "num_runs = 50  # Number of runs\n",
    "\n",
    "best_clusters = None\n",
    "best_prototypes = None\n",
    "best_score = float('inf')  # Minimize within-cluster distance\n",
    "best_prototype_index = None\n",
    "\n",
    "# Perform multiple runs\n",
    "for run in range(num_runs):\n",
    "    # Initialize clusters\n",
    "    clusters = [[] for _ in range(k)]\n",
    "\n",
    "    def assign_cluster(prototypes, clusters, point):\n",
    "        dissimilarities = []\n",
    "        for pt in prototypes:\n",
    "            v_n = num_matrix[point]\n",
    "            v_c = cat_matrix[point]\n",
    "            pt_v_n = pt[0]\n",
    "            pt_v_c = pt[1]\n",
    "            dissimilarity = dissimilarity_score(pt_v_c, v_c) + euclidian_distance(pt_v_n, v_n)\n",
    "            dissimilarities.append(dissimilarity)\n",
    "\n",
    "        dissimilarities = np.array(dissimilarities)\n",
    "        cluster = np.where(dissimilarities == dissimilarities.min())[0][0]\n",
    "        clusters[cluster].append((num_matrix[point], cat_matrix[point]))\n",
    "        return clusters\n",
    "\n",
    "    def calc_prototype(cluster):\n",
    "        if len(cluster) == 0:\n",
    "            # Return a placeholder prototype or handle as needed\n",
    "            return None  # or some default values\n",
    "        \n",
    "        num_cluster = np.vstack([point[0] for point in cluster])\n",
    "        num_prototype = np.mean(num_cluster, axis=0)\n",
    "        cat_cluster = np.vstack([point[1] for point in cluster])\n",
    "        cat_prototype = mode(cat_cluster, axis=0).mode[0]\n",
    "        return (num_prototype, cat_prototype)\n",
    "\n",
    "    # Main k-prototypes algorithm\n",
    "    while True:\n",
    "        for i in range(len(num_matrix)):\n",
    "            clusters = assign_cluster(prototypes, clusters, i)\n",
    "\n",
    "        # Calculate new prototypes\n",
    "        new_prototypes = [calc_prototype(cluster) for cluster in clusters]\n",
    "\n",
    "        # Check convergence\n",
    "        done = True\n",
    "        for i in range(len(prototypes)):\n",
    "            if not np.array_equal(prototypes[i][0], new_prototypes[i][0]) or \\\n",
    "               not np.array_equal(prototypes[i][1], new_prototypes[i][1]):\n",
    "                done = False\n",
    "                break\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        prototypes = new_prototypes\n",
    "        clusters = [[] for _ in range(k)]\n",
    "\n",
    "    # Evaluate within-cluster distance\n",
    "    total_distance = 0\n",
    "    for cluster_idx, cluster in enumerate(clusters):\n",
    "        for point in cluster:\n",
    "            num_distance = euclidian_distance(point[0], prototypes[cluster_idx][0])\n",
    "            cat_distance = dissimilarity_score(point[1], prototypes[cluster_idx][1])\n",
    "            total_distance += num_distance + cat_distance\n",
    "\n",
    "    # Update the best solution if this run is better\n",
    "    if total_distance < best_score:\n",
    "        best_score = total_distance\n",
    "        best_clusters = clusters\n",
    "        best_prototypes = prototypes\n",
    "        best_prototype_index = prototype_index\n",
    "\n",
    "# Print the best clustering result\n",
    "print(f\"Best clustering result found after {num_runs} runs:\")\n",
    "print(f\"Within-cluster distance: {best_score:.2f}\")\n",
    "for i, cluster in enumerate(best_clusters):\n",
    "    print(f\"Cluster {i + 1}: {len(cluster)} points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_prototype_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "cluster_data = [point[0] for cluster in best_clusters for point in cluster]\n",
    "cluster_labels = [i for i, cluster in enumerate(best_clusters) for _ in cluster]\n",
    "\n",
    "reduced_data = pca.fit_transform(cluster_data)\n",
    "plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=cluster_labels, cmap='tab10')\n",
    "plt.title(\"Cluster Visualization\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.colorbar(label=\"Cluster\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_reader\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Load data and prepare matrices\n",
    "# Load data from the Alzheimer's dataset\n",
    "# Assume column names might have trailing spaces, so strip them\n",
    "raw_data = data_reader.get_data_dict('./data/alzheimers_disease_data.csv')\n",
    "data = {key.strip(): value for key, value in raw_data.items()}\n",
    "\n",
    "# Define numerical and categorical columns\n",
    "num_cols = ['BMI', 'SystolicBP', 'DiastolicBP', 'CholesterolTotal', 'CholesterolLDL',\n",
    "    'CholesterolHDL', 'CholesterolTriglycerides', 'MMSE', 'FunctionalAssessment',\n",
    "    'AlcoholConsumption', 'PhysicalActivity', 'DietQuality', 'SleepQuality',\n",
    "    'ADL']\n",
    "cat_cols = ['FamilyHistoryAlzheimers', 'CardiovascularDisease', 'Diabetes',\n",
    "      'Depression', 'Hypertension', 'MemoryComplaints', 'BehavioralProblems',\n",
    "      'Confusion', 'Disorientation', 'PersonalityChanges', 'DifficultyCompletingTasks',\n",
    "      'Forgetfulness', 'HeadInjury', 'Smoking', 'Ethnicity', 'Gender',\n",
    "      'EducationLevel', 'Diagnosis']\n",
    "\n",
    "# Create matrices for numerical and categorical data\n",
    "num_matrix = np.vstack(tuple(data[col] for col in num_cols)).T\n",
    "cat_matrix = np.vstack(tuple(data[col] for col in cat_cols)).T\n",
    "\n",
    "# Dissimilarity and distance functions\n",
    "def dissimilarity_score(v1, v2):\n",
    "    return np.sum(v1 != v2)\n",
    "\n",
    "def euclidian_distance(v1, v2):\n",
    "    return np.sqrt(np.sum((v1 - v2)**2))\n",
    "\n",
    "# Initialize variables\n",
    "k = 4  # Number of clusters\n",
    "num_runs = 20  # Number of runs\n",
    "\n",
    "best_clusters = None\n",
    "best_prototypes = None\n",
    "best_score = float('inf')  # Minimize within-cluster distance\n",
    "best_prototype_index = None\n",
    "best_starting_indices = None  # To track the best starting indices\n",
    "\n",
    "# Perform multiple runs\n",
    "for run in range(num_runs):\n",
    "    # Randomly initialize prototypes\n",
    "    prototypes = np.random.randint(0, len(num_matrix), k)\n",
    "    prototype_index = prototypes\n",
    "    prototypes = [(num_matrix[i], cat_matrix[i]) for i in prototypes]\n",
    "\n",
    "    # Initialize clusters\n",
    "    clusters = [[] for _ in range(k)]\n",
    "\n",
    "    def assign_cluster(prototypes, clusters, point):\n",
    "        dissimilarities = []\n",
    "        for pt in prototypes:\n",
    "            v_n = num_matrix[point]\n",
    "            v_c = cat_matrix[point]\n",
    "            pt_v_n = pt[0]\n",
    "            pt_v_c = pt[1]\n",
    "            dissimilarity = dissimilarity_score(pt_v_c, v_c) + euclidian_distance(pt_v_n, v_n)\n",
    "            dissimilarities.append(dissimilarity)\n",
    "\n",
    "        dissimilarities = np.array(dissimilarities)\n",
    "        cluster = np.where(dissimilarities == dissimilarities.min())[0][0]\n",
    "        clusters[cluster].append((num_matrix[point], cat_matrix[point]))\n",
    "        return clusters\n",
    "\n",
    "    def calc_prototype(cluster):\n",
    "        if len(cluster) == 0:\n",
    "            return None  # Handle empty cluster case as needed\n",
    "        \n",
    "        num_cluster = np.vstack([point[0] for point in cluster])\n",
    "        num_prototype = np.mean(num_cluster, axis=0)\n",
    "        cat_cluster = np.vstack([point[1] for point in cluster])\n",
    "        cat_prototype = mode(cat_cluster, axis=0).mode[0]\n",
    "        return (num_prototype, cat_prototype)\n",
    "\n",
    "    # Main k-prototypes algorithm\n",
    "    while True:\n",
    "        for i in range(len(num_matrix)):\n",
    "            clusters = assign_cluster(prototypes, clusters, i)\n",
    "\n",
    "        # Calculate new prototypes\n",
    "        new_prototypes = [calc_prototype(cluster) for cluster in clusters]\n",
    "\n",
    "        # Check convergence\n",
    "        done = True\n",
    "        for i in range(len(prototypes)):\n",
    "            if not np.array_equal(prototypes[i][0], new_prototypes[i][0]) or \\\n",
    "               not np.array_equal(prototypes[i][1], new_prototypes[i][1]):\n",
    "                done = False\n",
    "                break\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        prototypes = new_prototypes\n",
    "        clusters = [[] for _ in range(k)]\n",
    "\n",
    "    # Evaluate within-cluster distance\n",
    "    total_distance = 0\n",
    "    for cluster_idx, cluster in enumerate(clusters):\n",
    "        for point in cluster:\n",
    "            num_distance = euclidian_distance(point[0], prototypes[cluster_idx][0])\n",
    "            cat_distance = dissimilarity_score(point[1], prototypes[cluster_idx][1])\n",
    "            total_distance += num_distance + cat_distance\n",
    "\n",
    "    # Update the best solution if this run is better\n",
    "    if total_distance < best_score:\n",
    "        best_score = total_distance\n",
    "        best_clusters = clusters\n",
    "        best_prototypes = prototypes\n",
    "        best_prototype_index = prototype_index\n",
    "        best_starting_indices = starting_indices  # Save the starting indices\n",
    "\n",
    "# Print the best clustering result\n",
    "print(f\"Best clustering result found after {num_runs} runs:\")\n",
    "print(f\"Within-cluster distance: {best_score:.2f}\")\n",
    "for i, cluster in enumerate(best_clusters):\n",
    "    print(f\"Cluster {i + 1}: {len(cluster)} points\")\n",
    "\n",
    "# Print the starting indices for reproducibility\n",
    "print(f\"Best starting indices for reproducibility: {best_starting_indices}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproduce results\n",
    "# Initialize prototypes using the best starting indices\n",
    "prototypes = best_starting_indices\n",
    "#prototypes = [1058,  598,   42, 1106, 1647]\n",
    "prototypes = [(num_matrix[i], cat_matrix[i]) for i in prototypes]\n",
    "prototypes = np.random.randint(0, len(num_matrix), k)\n",
    "prototype_index = prototypes\n",
    "prototypes = [(num_matrix[i], cat_matrix[i]) for i in prototypes]\n",
    "\n",
    "# Run the k-prototypes algorithm once with these prototypes to reproduce the result\n",
    "clusters = [[] for _ in range(k)]\n",
    "while True:\n",
    "    for i in range(len(num_matrix)):\n",
    "        clusters = assign_cluster(prototypes, clusters, i)\n",
    "\n",
    "    # Calculate new prototypes\n",
    "    new_prototypes = [calc_prototype(cluster) for cluster in clusters]\n",
    "\n",
    "    # Check convergence\n",
    "    done = True\n",
    "    for i in range(len(prototypes)):\n",
    "        if not np.array_equal(prototypes[i][0], new_prototypes[i][0]) or \\\n",
    "           not np.array_equal(prototypes[i][1], new_prototypes[i][1]):\n",
    "            done = False\n",
    "            break\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "    prototypes = new_prototypes\n",
    "    clusters = [[] for _ in range(k)]\n",
    "\n",
    "print(\"Reproduced clustering result:\")\n",
    "for i, cluster in enumerate(clusters):\n",
    "    print(f\"Cluster {i + 1}: {len(cluster)} points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "cluster_data = [point[0] for cluster in clusters for point in cluster]\n",
    "cluster_labels = [i for i, cluster in enumerate(clusters) for _ in cluster]\n",
    "\n",
    "reduced_data = pca.fit_transform(cluster_data)\n",
    "plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=cluster_labels)\n",
    "plt.title(\"Cluster Visualization\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.colorbar(label=\"Cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "modes = []\n",
    "ratios = []\n",
    "for cluster in clusters:\n",
    "    cluster_num_matrix = np.array([item[0] for item in cluster])\n",
    "    cluster_cat_matrix = np.array([item[1] for item in cluster])\n",
    "    diagnosis = cluster_cat_matrix[:, -1]\n",
    "    count_zeros = np.sum(diagnosis == 0)\n",
    "    count_ones = np.sum(diagnosis == 1)\n",
    "    ratios.append(count_ones/(count_zeros + count_ones))\n",
    "    cluster_means = np.mean(cluster_num_matrix, axis=0)\n",
    "    cluster_modes = mode(cluster_cat_matrix, axis=0).mode\n",
    "    means.append(cluster_means)\n",
    "    modes.append(cluster_modes)\n",
    "\n",
    "\n",
    "print('-- Ratios of diagnosis --')\n",
    "print(ratios)\n",
    "\n",
    "print('-- Numerical Columns means --')\n",
    "for i in range(len(num_cols)):\n",
    "    print(num_cols[i])\n",
    "    print([mean[i] for mean in means])\n",
    "\n",
    "print('-- Categorical Columns modes --')\n",
    "for i in range(len(cat_cols)):\n",
    "    print(cat_cols[i])\n",
    "    print([mode[i] for mode in modes])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
