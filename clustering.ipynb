{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Using clustering, we may be able to find particular clusters of patients that have a higher amount of Alzheimer's disease than others. Then, based on the differences between clusters, we might be able to find a pattern. For the clustering, $k$-prototypes clustering is used, since it is easy to implement, fast and it works on mixed data, which is the case for our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_reader\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "\n",
    "data = data_reader.get_data_dict('./data/alzheimers_disease_data.csv')\n",
    "num_cols = ['BMI', 'SystolicBP', 'DiastolicBP', 'CholesterolTotal', 'CholesterolLDL',\n",
    "    'CholesterolHDL', 'CholesterolTriglycerides', 'MMSE', 'FunctionalAssessment',\n",
    "    'AlcoholConsumption', 'PhysicalActivity', 'DietQuality', 'SleepQuality',\n",
    "    'ADL']\n",
    "cat_cols = ['FamilyHistoryAlzheimers', 'CardiovascularDisease', 'Diabetes',\n",
    "      'Depression', 'Hypertension', 'MemoryComplaints', 'BehavioralProblems',\n",
    "      'Confusion', 'Disorientation', 'PersonalityChanges', 'DifficultyCompletingTasks',\n",
    "      'Forgetfulness', 'HeadInjury', 'Smoking', 'Ethnicity', 'Gender',\n",
    "      'EducationLevel', 'Diagnosis']\n",
    "\n",
    "num_matrix = np.vstack(tuple(data[col] for col in num_cols)).T\n",
    "cat_matrix = np.vstack(tuple(data[col] for col in cat_cols)).T\n",
    "\n",
    "\n",
    "def dissimilarity_score(v1, v2):\n",
    "    # Calculate the amount of differences between categorical features\n",
    "    differences = v1 != v2\n",
    "    return np.sum(differences)\n",
    "\n",
    "\n",
    "def euclidian_distance(v1, v2):\n",
    "    # Calculate the euclidian distance between numerical features\n",
    "    return np.sqrt(np.sum((v1 - v2)**2))\n",
    "\n",
    "\n",
    "def assign_cluster(prototypes, clusters, point):\n",
    "    dissimilarities = []\n",
    "    for pt in prototypes:\n",
    "        v_n = num_matrix[point]\n",
    "        v_c = cat_matrix[point]\n",
    "        pt_v_n = pt[0]\n",
    "        pt_v_c = pt[1]\n",
    "        dissimilarity = dissimilarity_score(pt_v_n, v_n) + euclidian_distance(pt_v_c, v_c)\n",
    "        dissimilarities.append(dissimilarity)\n",
    "\n",
    "    dissimilarities = np.array(dissimilarities)\n",
    "    cluster = np.where(dissimilarities == dissimilarities.min())[0][0]\n",
    "    clusters[cluster].append((num_matrix[point], cat_matrix[point]))\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def calc_prototype(cluster):\n",
    "    # Calculate a new prototype\n",
    "    num_cluster = np.vstack([point[0] for point in cluster])\n",
    "    num_prototype = np.mean(num_cluster, axis=0)\n",
    "    cat_cluster = np.vstack([point[1] for point in cluster])\n",
    "    cat_prototype = mode(cat_cluster, axis=0).mode\n",
    "\n",
    "    return (num_prototype, cat_prototype)\n",
    "\n",
    "\n",
    "def cluster_data(k, num_matrix, cat_matrix, verbose=False):\n",
    "    prototypes = np.random.randint(0, len(num_matrix), k)\n",
    "    if verbose:\n",
    "        print(f'Selected initial prototypes: {prototypes}')\n",
    "\n",
    "    # Initialize prototypes and clusters\n",
    "    prototypes = [(num_matrix[i], cat_matrix[i]) for i in prototypes]\n",
    "    clusters = [[] for _ in range(k)]\n",
    "\n",
    "    while True:\n",
    "        for i in range(len(num_matrix)):\n",
    "            clusters = assign_cluster(prototypes, clusters, i)\n",
    "\n",
    "        # Calculate new prototypes\n",
    "        new_prototypes = [calc_prototype(cluster) for cluster in clusters]\n",
    "\n",
    "        # Check for convergence\n",
    "        done = all(\n",
    "            np.array_equal(prototypes[i][0], new_prototypes[i][0]) and\n",
    "            np.array_equal(prototypes[i][1], new_prototypes[i][1])\n",
    "            for i in range(len(prototypes))\n",
    "        )\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        prototypes = new_prototypes\n",
    "        clusters = [[] for _ in range(k)]\n",
    "\n",
    "    if verbose:\n",
    "        print(f'---  {len(clusters)} clusters found  ---')\n",
    "        for i, cluster in enumerate(clusters):\n",
    "            print(f' - Cluster {i + 1} with size={len(cluster)}')\n",
    "\n",
    "    return clusters\n",
    "\n",
    "# k indicates the amount of clusters\n",
    "k = 5\n",
    "clusters = cluster_data(k, num_matrix, cat_matrix, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are now $k$ clusters, we can try to find differences between the clusters. The first thing to do is to find the ratio of people with and without a diagnosis per cluster, from there, we can see which other variables show behaviour that is distinct for a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns are organized in the same order as the num_cols and cat_cols\n",
    "# variables defined in the cell above\n",
    "ratios = []\n",
    "for cluster in clusters:\n",
    "    diagnosis_amt = 0\n",
    "    for item in cluster:\n",
    "        if item[1][-1] == 1:\n",
    "            diagnosis_amt += 1\n",
    "    ratios.append(diagnosis_amt/len(cluster))\n",
    "\n",
    "print('Percentage of patients with a diagnosis')\n",
    "for i in range(len(ratios)):\n",
    "    print(f' - in cluster {i + 1}: {ratios[i]*100}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the initial prototypes, the clusters have a different percentage of patients on each execution of the algorithm. However, in most of the runs of the algorithm there are a few clusters that have a diagnosis percentage of over 50%, while there are others with a percentage at 25% or lower. Occasionally, each cluster has about the same ratio of patients with a diagnosis compared to patients without one, which is not that useful.\n",
    "\n",
    "It might be best to run the clustering algorithm a few times to find initial prototypes that produce clusters with significant differences in the percentage of patients with a diagnosis, so we can look at which variables are also responsible for that difference. These same prototypes can then be stored so they can be re-used later."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
