{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_score, recall_score, f1_score,\n",
    "    roc_curve, auc, confusion_matrix\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "from scipy.stats import chi2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/alzheimers_disease_data.csv'\n",
    "alzheimers_data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_factors_keys = [\n",
    "    \"Age\", \"Gender\", \"Ethnicity\", \"BMI\", \"FamilyHistoryAlzheimers\",\n",
    "    \"CardiovascularDisease\", \"Diabetes\", \"Depression\", \"Hypertension\",\n",
    "    \"SystolicBP\", \"DiastolicBP\", \"CholesterolTotal\", \"CholesterolLDL\",\n",
    "    \"CholesterolHDL\", \"CholesterolTriglycerides\", \"MMSE\", \"FunctionalAssessment\",\n",
    "    \"MemoryComplaints\", \"BehavioralProblems\", \"ADL\", \"Confusion\",\n",
    "    \"Disorientation\", \"PersonalityChanges\", \"DifficultyCompletingTasks\",\n",
    "    \"Forgetfulness\", \"HeadInjury\"\n",
    "]\n",
    "external_factors_keys = [\"EducationLevel\", \"Smoking\", \"AlcoholConsumption\",\n",
    "                         \"PhysicalActivity\", \"DietQuality\", \"SleepQuality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = alzheimers_data\n",
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "\n",
    "Using forward modelling selection with the usage of BIC, we tried to find variables to use for the logistic regression model. In the first code box below, we used the five variables that showed a (small) correlation in the visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model with ['MemoryComplaints', 'BehavioralProblems',\n",
    "#                                 'MMSE', 'ADL', 'FunctionalAssessment']\n",
    "\n",
    "y = alzheimers_data['Diagnosis'].astype(int)\n",
    "X = alzheimers_data[['MemoryComplaints', 'BehavioralProblems', 'MMSE', 'ADL', 'FunctionalAssessment']]\n",
    "X_sm = sm.add_constant(X)\n",
    "\n",
    "model = sm.Logit(y, X_sm).fit()\n",
    "print(model.summary())\n",
    "\n",
    "bic_value = model.bic\n",
    "print(f\"BIC value for the given model: {bic_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes the predictors and calculates which model is the best with the use of BIC. The code below looks at the variables and adds the one with the best (lowest) BIC score. It keeps on doing this until it cannot imnprove the BIC score anymore. Then, it adds the remaining variables so you can see in the graph that the BIC score gets worse the more variables you add from that point on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we combine the factors to use all the predictors.\n",
    "predictors = internal_factors_keys + external_factors_keys\n",
    "\n",
    "\n",
    "def fit_model(X):\n",
    "    X_sm = sm.add_constant(X)\n",
    "    model_sm = sm.Logit(y, X_sm).fit(disp=0)\n",
    "    return model_sm.bic, model_sm\n",
    "\n",
    "\n",
    "def print_model_formula(model, predictors):\n",
    "    coef = model.params\n",
    "    formula = f\"y = {coef.iloc[0]:.4f}\"  # Intercept\n",
    "    for i, predictor in enumerate(predictors):\n",
    "        formula += f\" + ({coef.iloc[i + 1]:.4f} * {predictor})\"\n",
    "    print(\"Logistic Regression Formula:\")\n",
    "    print(formula)\n",
    "\n",
    "\n",
    "bic_values = []\n",
    "best_bic = float('inf')\n",
    "best_model = None\n",
    "selected_predictors = []\n",
    "remaining_predictors = set(predictors)\n",
    "\n",
    "# Step 1: Find the best initial predictor\n",
    "best_initial_bic = float('inf')\n",
    "best_initial_predictor = None\n",
    "\n",
    "for predictor in remaining_predictors:\n",
    "    X = alzheimers_data[[predictor]]\n",
    "    bic, _ = fit_model(X)\n",
    "    if bic < best_initial_bic:\n",
    "        best_initial_bic = bic\n",
    "        best_initial_predictor = predictor\n",
    "\n",
    "selected_predictors.append(best_initial_predictor)\n",
    "bic_values.append(best_initial_bic)\n",
    "best_bic = best_initial_bic\n",
    "remaining_predictors.remove(best_initial_predictor)\n",
    "\n",
    "# Step 2: Iteratively add predictors that improve the BIC\n",
    "while remaining_predictors:\n",
    "    best_new_bic = float('inf')\n",
    "    best_new_predictor = None\n",
    "\n",
    "    for predictor in remaining_predictors:\n",
    "        X = alzheimers_data[selected_predictors + [predictor]]\n",
    "        bic, _ = fit_model(X)\n",
    "        if bic < best_new_bic:\n",
    "            best_new_bic = bic\n",
    "            best_new_predictor = predictor\n",
    "\n",
    "    # Check if adding the new predictor improves the BIC\n",
    "    if best_new_bic < best_bic:\n",
    "        best_bic = best_new_bic\n",
    "        selected_predictors.append(best_new_predictor)\n",
    "        bic_values.append(best_bic)\n",
    "        remaining_predictors.remove(best_new_predictor)\n",
    "\n",
    "        # Save the current best model\n",
    "        X_best = alzheimers_data[selected_predictors]\n",
    "        X_best_sm = sm.add_constant(X_best)\n",
    "        _, best_model = fit_model(X_best)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Step 3: Add remaining predictors to complete the graph\n",
    "for predictor in remaining_predictors:\n",
    "    selected_predictors.append(predictor)\n",
    "    X = alzheimers_data[selected_predictors]\n",
    "    bic, _ = fit_model(X)\n",
    "    bic_values.append(bic)\n",
    "\n",
    "print(f\"Best combination of predictors: {selected_predictors[:bic_values.index(best_bic) + 1]}\")\n",
    "print(f\"Best BIC: {best_bic}\")\n",
    "print(best_model.summary())\n",
    "print_model_formula(best_model, selected_predictors[:bic_values.index(best_bic) + 1])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(bic_values) + 1), bic_values, marker='o', linestyle='-', color='b')\n",
    "plt.title('BIC vs Number of Predictors')\n",
    "plt.xlabel('Number of Predictors')\n",
    "plt.ylabel('BIC')\n",
    "plt.xticks(range(1, len(bic_values) + 1))\n",
    "plt.axvline(x=bic_values.index(best_bic) + 1, color='r', linestyle='--', label='Best Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on, the same is done but the columns are seperated based on the ethnicity. So per column, 4 new columns are added (for ethnicity 0-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = alzheimers_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all predictors\n",
    "all_predictors = internal_factors_keys + external_factors_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_on_ethnicity = []\n",
    "\n",
    "# Create subset columns and add their names to the list\n",
    "for predictor in all_predictors:\n",
    "    for ethnicity in df_2['Ethnicity'].unique():\n",
    "        col_name = f'{predictor}_{ethnicity}'\n",
    "        df_2[col_name] = df_2.loc[df_2['Ethnicity'] == ethnicity, predictor].fillna(0)\n",
    "        predictors_on_ethnicity.append(col_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_df_to_csv(df, file_name):\n",
    "    \"\"\"\n",
    "    Writes the provided DataFrame to a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame to write.\n",
    "    file_name (str): The name of the CSV file to save the DataFrame.\n",
    "    \"\"\"\n",
    "    df.to_csv(file_name, index=False)  # index=False prevents writing row indices\n",
    "    print(f\"DataFrame successfully written to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_df_to_csv(df_2, 'analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below fills in all the Nan in the dataframe. It does this by firstly iterating over all columns. In the column, it checks if there are any Nan. If it finds a Nan, it looks at the diagnosis of the row. Then, it takes a random value out of that column with the same diagnosis score and fills it in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the Nan by randomly replacing it by another value of that column,\n",
    "# but checking if the 'diagnosis' value is the same of the one that it replaces\n",
    "# it with.\n",
    "\n",
    "\n",
    "def random_impute_by_diagnosis(df, column, diagnosis_column='Diagnosis'):\n",
    "    for idx, row in df.iterrows():\n",
    "        if pd.isna(row[column]):\n",
    "            diagnosis_value = row[diagnosis_column]\n",
    "            subset = df[df[diagnosis_column] == diagnosis_value]\n",
    "\n",
    "            # Get the non-NaN values of the current column from the subset\n",
    "            non_missing_values = subset[column].dropna().values\n",
    "\n",
    "            if len(non_missing_values) > 0:\n",
    "                # Randomly select a value from the non-missing values\n",
    "                random_value = np.random.choice(non_missing_values)\n",
    "\n",
    "                # Replace the NaN with the randomly selected value\n",
    "                df.at[idx, column] = random_value\n",
    "\n",
    "    print(f\"Imputation for column '{column}' completed successfully.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_2.columns\n",
    "for column in columns:\n",
    "    df_2 = random_impute_by_diagnosis(df_2, column)\n",
    "\n",
    "# This can take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because it took 30 minutes to make this df, it is saved to a csv file so it\n",
    "# can easily be read again when opening up ipynb again instead of having to do\n",
    "# this all over again.\n",
    "write_df_to_csv(df_3, 'analysis_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop these ethnicity columns since we are already looking at them per variable\n",
    "df_3.drop(columns=['Ethnicity_0'], inplace=True)\n",
    "df_3.drop(columns=['Ethnicity_1'], inplace=True)\n",
    "df_3.drop(columns=['Ethnicity_2'], inplace=True)\n",
    "df_3.drop(columns=['Ethnicity_3'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the ethnicity column names in the list with column names\n",
    "predictors_2 = predictors_on_ethnicity\n",
    "predictors_2.remove(\"Ethnicity_0\")\n",
    "predictors_2.remove(\"Ethnicity_1\")\n",
    "predictors_2.remove(\"Ethnicity_2\")\n",
    "predictors_2.remove(\"Ethnicity_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Down here is the logistic regression fit again and the BIC used to determine the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the target variable (Diagnosis) and predictor variables \n",
    "y = df_3['Diagnosis'].astype(int)\n",
    "\n",
    "# Create a list of all potential predictor variables\n",
    "predictors = predictors_2\n",
    "\n",
    "\n",
    "def fit_model(X):\n",
    "    \"\"\"\n",
    "    # Function to fit logistic regression and calculate BIC\n",
    "    def fit_model(X):\n",
    "        X_sm = sm.add_constant(X)  # Add a constant for the intercept term\n",
    "        model_sm = sm.Logit(y, X_sm).fit(disp=0)  # Fit the logistic regression model\n",
    "        return model_sm.bic, model_sm  # Return the BIC value and model\n",
    "    \"\"\"\n",
    "    X_sm = sm.add_constant(X)  # Add a constant for the intercept term\n",
    "    try:\n",
    "        model_sm = sm.Logit(y, X_sm).fit(disp=0)  # Fit the logistic regression model\n",
    "        return model_sm.bic, model_sm  # Return the BIC value and model\n",
    "    except np.linalg.LinAlgError:  # Catch singular matrix error\n",
    "        print(\"Singular matrix error with predictors:\", X.columns)\n",
    "        return np.inf, None  # Return an infinite BIC value to discard this model\n",
    "\n",
    "\n",
    "def print_model_formula(model, predictors):\n",
    "    coef = model.params\n",
    "    formula = f\"y = {coef.iloc[0]:.4f}\"  # Intercept\n",
    "    for i, predictor in enumerate(predictors):\n",
    "        formula += f\" + ({coef.iloc[i + 1]:.4f} * {predictor})\"\n",
    "    print(\"Logistic Regression Formula:\")\n",
    "    print(formula)\n",
    "\n",
    "\n",
    "bic_values = []\n",
    "best_bic = float('inf')\n",
    "best_model = None\n",
    "selected_predictors = []\n",
    "remaining_predictors = set(predictors)\n",
    "\n",
    "# Step 1: Find the best initial predictor\n",
    "best_initial_bic = float('inf')\n",
    "best_initial_predictor = None\n",
    "\n",
    "for predictor in remaining_predictors:\n",
    "    X = df_3[[predictor]]\n",
    "    bic, _ = fit_model(X)\n",
    "    if bic < best_initial_bic:\n",
    "        best_initial_bic = bic\n",
    "        best_initial_predictor = predictor\n",
    "\n",
    "selected_predictors.append(best_initial_predictor)\n",
    "bic_values.append(best_initial_bic)\n",
    "best_bic = best_initial_bic\n",
    "remaining_predictors.remove(best_initial_predictor)\n",
    "\n",
    "# Step 2: Iteratively add predictors that improve the BIC\n",
    "while remaining_predictors:\n",
    "    best_new_bic = float('inf')\n",
    "    best_new_predictor = None\n",
    "\n",
    "    for predictor in remaining_predictors:\n",
    "        X = df_3[selected_predictors + [predictor]]\n",
    "        bic, _ = fit_model(X)\n",
    "        if bic < best_new_bic:\n",
    "            best_new_bic = bic\n",
    "            best_new_predictor = predictor\n",
    "\n",
    "    if best_new_bic < best_bic:\n",
    "        best_bic = best_new_bic\n",
    "        selected_predictors.append(best_new_predictor)\n",
    "        bic_values.append(best_bic)\n",
    "        remaining_predictors.remove(best_new_predictor)\n",
    "\n",
    "        X_best = df_3[selected_predictors]\n",
    "        X_best_sm = sm.add_constant(X_best)\n",
    "        _, best_model = fit_model(X_best)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Step 3: Add remaining predictors to complete the graph\n",
    "for predictor in remaining_predictors:\n",
    "    selected_predictors.append(predictor)\n",
    "    X = df_3[selected_predictors]\n",
    "    bic, _ = fit_model(X)\n",
    "    bic_values.append(bic)\n",
    "\n",
    "print(f\"Best combination of predictors: {selected_predictors[:bic_values.index(best_bic) + 1]}\")\n",
    "print(f\"Best BIC: {best_bic}\")\n",
    "print(best_model.summary())\n",
    "print_model_formula(best_model, selected_predictors[:bic_values.index(best_bic) + 1])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(bic_values) + 1), bic_values, marker='o', linestyle='-', color='b')\n",
    "plt.title('BIC vs Number of Predictors')\n",
    "plt.xlabel('Number of Predictors')\n",
    "plt.ylabel('BIC')\n",
    "plt.xticks(range(1, len(bic_values) + 1, 10))\n",
    "plt.axvline(x=bic_values.index(best_bic) + 1, color='r', linestyle='--', label='Best Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on, the same is done as above. So the logistic regression is fit with the help of BIC. However, since making the dataframe with the columns seperated on ethnicity took very long, if the outputs are somehow deleted, down here is a quicker version that reads the already edited csv file in a dataframe. As you can see all the way at the bottom, the results are the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'analysis_2.csv'\n",
    "alzheimers_data_new_columns = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_regression_bic(df, predictors):\n",
    "    y = df['Diagnosis'].astype(int)\n",
    "\n",
    "    # Create a list of all potential predictor variables\n",
    "    predictors = predictors\n",
    "\n",
    "    def fit_model(X):\n",
    "        \"\"\"\n",
    "        # Function to fit logistic regression and calculate BIC\n",
    "        def fit_model(X):\n",
    "            X_sm = sm.add_constant(X)  # Add a constant for the intercept term\n",
    "            model_sm = sm.Logit(y, X_sm).fit(disp=0)  # Fit the logistic regression model\n",
    "            return model_sm.bic, model_sm  # Return the BIC value and model\n",
    "        \"\"\"\n",
    "        X_sm = sm.add_constant(X)  # Add a constant for the intercept term\n",
    "        try:\n",
    "            model_sm = sm.Logit(y, X_sm).fit(disp=0)  # Fit the logistic regression model\n",
    "            return model_sm.bic, model_sm  # Return the BIC value and model\n",
    "        except np.linalg.LinAlgError:  # Catch singular matrix error\n",
    "            print(\"Singular matrix error with predictors:\", X.columns)\n",
    "            return np.inf, None  # Return an infinite BIC value to discard this model\n",
    "\n",
    "    def print_model_formula(model, predictors):\n",
    "        coef = model.params\n",
    "        formula = f\"y = {coef.iloc[0]:.4f}\"  # Intercept\n",
    "        for i, predictor in enumerate(predictors):\n",
    "            formula += f\" + ({coef.iloc[i + 1]:.4f} * {predictor})\"\n",
    "        print(\"Logistic Regression Formula:\")\n",
    "        print(formula)\n",
    "\n",
    "    bic_values = []\n",
    "    best_bic = float('inf')\n",
    "    best_model = None\n",
    "    selected_predictors = []\n",
    "    remaining_predictors = set(predictors)\n",
    "\n",
    "    # Step 1: Find the best initial predictor\n",
    "    best_initial_bic = float('inf')\n",
    "    best_initial_predictor = None\n",
    "\n",
    "    for predictor in remaining_predictors:\n",
    "        X = df[[predictor]]\n",
    "        bic, _ = fit_model(X)\n",
    "        if bic < best_initial_bic:\n",
    "            best_initial_bic = bic\n",
    "            best_initial_predictor = predictor\n",
    "\n",
    "    # Update lists and variables after selecting the first predictor\n",
    "    selected_predictors.append(best_initial_predictor)\n",
    "    bic_values.append(best_initial_bic)\n",
    "    best_bic = best_initial_bic\n",
    "    remaining_predictors.remove(best_initial_predictor)\n",
    "\n",
    "    # Step 2: Iteratively add predictors that improve the BIC\n",
    "    while remaining_predictors:\n",
    "        best_new_bic = float('inf')\n",
    "        best_new_predictor = None\n",
    "\n",
    "        for predictor in remaining_predictors:\n",
    "            X = df[selected_predictors + [predictor]]\n",
    "            bic, _ = fit_model(X)\n",
    "            if bic < best_new_bic:\n",
    "                best_new_bic = bic\n",
    "                best_new_predictor = predictor\n",
    "\n",
    "        if best_new_bic < best_bic:\n",
    "            best_bic = best_new_bic\n",
    "            selected_predictors.append(best_new_predictor)\n",
    "            bic_values.append(best_bic)\n",
    "            remaining_predictors.remove(best_new_predictor)\n",
    "\n",
    "            X_best = df[selected_predictors]\n",
    "            X_best_sm = sm.add_constant(X_best)\n",
    "            _, best_model = fit_model(X_best)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Step 3: Add remaining predictors to complete the graph\n",
    "    for predictor in remaining_predictors:\n",
    "        selected_predictors.append(predictor)\n",
    "        X = df[selected_predictors]\n",
    "        bic, _ = fit_model(X)\n",
    "        bic_values.append(bic)\n",
    "\n",
    "    print(f\"Best combination of predictors: {selected_predictors[:bic_values.index(best_bic) + 1]}\")\n",
    "    print(f\"Best BIC: {best_bic}\")\n",
    "    print(best_model.summary())\n",
    "    print_model_formula(best_model, selected_predictors[:bic_values.index(best_bic) + 1])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, len(bic_values) + 1), bic_values, marker='o', linestyle='-', color='b')\n",
    "    plt.title('BIC vs Number of Predictors')\n",
    "    plt.xlabel('Number of Predictors')\n",
    "    plt.ylabel('BIC')\n",
    "    plt.xticks(range(1, len(bic_values) + 1, 10))\n",
    "    plt.axvline(x=bic_values.index(best_bic) + 1, color='r', linestyle='--', label='Best Model')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alzheimers_data_new_columns.columns = alzheimers_data_new_columns.columns.str.strip()\n",
    "alzheimers_data_new_columns.drop(columns=['Ethnicity_0'], inplace=True)\n",
    "alzheimers_data_new_columns.drop(columns=['Ethnicity_1'], inplace=True)\n",
    "alzheimers_data_new_columns.drop(columns=['Ethnicity_2'], inplace=True)\n",
    "alzheimers_data_new_columns.drop(columns=['Ethnicity_3'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_regression_bic(df=alzheimers_data_new_columns, predictors=predictors_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the network, we used 80% of the data to train it and 20% to test it (cross-validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = alzheimers_data['Diagnosis'].astype(int)\n",
    "X = alzheimers_data[['MemoryComplaints', 'BehavioralProblems', 'MMSE', 'ADL', 'FunctionalAssessment']]\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "\n",
    "model = sm.Logit(y_train, X_train_sm).fit()\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "X_test_sm = sm.add_constant(X_test)\n",
    "y_pred = model.predict(X_test_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hosmer-Lemeshow test is a statistical test used to assess how well a logistic regression model fits the observed data. It is commonly used to check if the predicted probabilities from the model match the actual outcomes. It tests whether the observed event rates match the expected event rates in subgroups of the data.\n",
    "\n",
    "The test works by grouping predicted probabilities into intervals (deciles), calculating the observed and expected number of events (e.g., binary outcomes like success/failure), and comparing them. A significant p-value (typically < 0.05) suggests that the model does not fit the data well, while a non-significant p-value suggests that the model fits the data adequately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hosmer-Lemeshow Goodness-of-Fit Test\n",
    "data = X_test.copy()\n",
    "data['predicted'] = y_pred\n",
    "data['actual'] = y_test\n",
    "\n",
    "# Group predictions into deciles\n",
    "data['decile'] = pd.qcut(data['predicted'], 10, labels=False)\n",
    "\n",
    "# Calculate observed and expected counts\n",
    "observed = data.groupby('decile')['actual'].sum()\n",
    "expected = data.groupby('decile')['predicted'].sum()\n",
    "\n",
    "# Compute HL test statistic\n",
    "hl_stat = ((observed - expected) ** 2 / expected).sum()\n",
    "p_value = chi2.sf(hl_stat, df=8)  # Degrees of freedom = number of deciles - 2\n",
    "\n",
    "print(f\"Hosmer-Lemeshow Test Statistic: {hl_stat:.2f}, p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the observed and expected counts (this part remains the same from before)\n",
    "observed = data.groupby('decile')['actual'].sum()\n",
    "expected = data.groupby('decile')['predicted'].sum()\n",
    "\n",
    "# Compute the Pearson chi-squared test statistic\n",
    "chi_squared_stat = ((observed - expected) ** 2 / expected).sum()\n",
    "\n",
    "# Degrees of freedom = number of deciles - 1\n",
    "# Since there are 10 deciles, the degrees of freedom will be 10 - 1 = 9\n",
    "df = len(observed) - 1\n",
    "\n",
    "# Compute the p-value\n",
    "p_value = chi2.sf(chi_squared_stat, df)\n",
    "\n",
    "# Output the result\n",
    "print(f\"Pearson Chi-Squared Test Statistic: {chi_squared_stat:.2f}, p-value: {p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration Curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_pred, n_bins=10)\n",
    "\n",
    "# Plot calibration curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(prob_pred, prob_true, marker='o', label='Model')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
    "plt.xlabel('Mean Predicted Probability')\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Calibration Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Metrics Evaluation\n",
    "# Convert predicted probabilities to binary labels (0 or 1)\n",
    "y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "# ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Precision, Recall, F1-Score\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "recall = recall_score(y_test, y_pred_binary)\n",
    "f1 = f1_score(y_test, y_pred_binary)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# ROC Curve Plot\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc_value = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc_value:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
